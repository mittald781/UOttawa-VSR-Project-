{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = pd.read_stata(\"./compustat_crsp_merged_1989_2019_identifier.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_database = database.sort_values(by=\"cik\", kind=\"mergesort\").reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_database['datayear'] = pd.DatetimeIndex(sorted_database['datadate']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>lpermno</th>\n",
       "      <th>lpermco</th>\n",
       "      <th>datadate</th>\n",
       "      <th>fyear</th>\n",
       "      <th>tic</th>\n",
       "      <th>cusip</th>\n",
       "      <th>conm</th>\n",
       "      <th>cik</th>\n",
       "      <th>sich</th>\n",
       "      <th>sic</th>\n",
       "      <th>datayear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001038</td>\n",
       "      <td>66413.0</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>1989-03-31</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>AEN.2</td>\n",
       "      <td>001669100</td>\n",
       "      <td>AMC ENTERTAINMENT INC -OLD</td>\n",
       "      <td></td>\n",
       "      <td>7830.0</td>\n",
       "      <td>7830</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001038</td>\n",
       "      <td>66413.0</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>1990-03-31</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>AEN.2</td>\n",
       "      <td>001669100</td>\n",
       "      <td>AMC ENTERTAINMENT INC -OLD</td>\n",
       "      <td></td>\n",
       "      <td>7830.0</td>\n",
       "      <td>7830</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001038</td>\n",
       "      <td>66413.0</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>1991-03-31</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>AEN.2</td>\n",
       "      <td>001669100</td>\n",
       "      <td>AMC ENTERTAINMENT INC -OLD</td>\n",
       "      <td></td>\n",
       "      <td>7830.0</td>\n",
       "      <td>7830</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001038</td>\n",
       "      <td>66413.0</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>1992-03-31</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>AEN.2</td>\n",
       "      <td>001669100</td>\n",
       "      <td>AMC ENTERTAINMENT INC -OLD</td>\n",
       "      <td></td>\n",
       "      <td>7830.0</td>\n",
       "      <td>7830</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001038</td>\n",
       "      <td>66413.0</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>1993-03-31</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>AEN.2</td>\n",
       "      <td>001669100</td>\n",
       "      <td>AMC ENTERTAINMENT INC -OLD</td>\n",
       "      <td></td>\n",
       "      <td>7830.0</td>\n",
       "      <td>7830</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204988</th>\n",
       "      <td>066336</td>\n",
       "      <td>89498.0</td>\n",
       "      <td>43502.0</td>\n",
       "      <td>2005-12-31</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>TSBA</td>\n",
       "      <td>89157H106</td>\n",
       "      <td>TOUCHSTONE BANKSHARES INC</td>\n",
       "      <td>0001821297</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>6020</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204989</th>\n",
       "      <td>066336</td>\n",
       "      <td>89498.0</td>\n",
       "      <td>43502.0</td>\n",
       "      <td>2006-12-31</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>TSBA</td>\n",
       "      <td>89157H106</td>\n",
       "      <td>TOUCHSTONE BANKSHARES INC</td>\n",
       "      <td>0001821297</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>6020</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204990</th>\n",
       "      <td>066336</td>\n",
       "      <td>89498.0</td>\n",
       "      <td>43502.0</td>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>TSBA</td>\n",
       "      <td>89157H106</td>\n",
       "      <td>TOUCHSTONE BANKSHARES INC</td>\n",
       "      <td>0001821297</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>6020</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204991</th>\n",
       "      <td>066336</td>\n",
       "      <td>89498.0</td>\n",
       "      <td>43502.0</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>TSBA</td>\n",
       "      <td>89157H106</td>\n",
       "      <td>TOUCHSTONE BANKSHARES INC</td>\n",
       "      <td>0001821297</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>6020</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204992</th>\n",
       "      <td>176828</td>\n",
       "      <td>18459.0</td>\n",
       "      <td>56685.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>CARE</td>\n",
       "      <td>146103106</td>\n",
       "      <td>CARTER BANKSHARES INC</td>\n",
       "      <td>0001829576</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>6020</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204993 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         gvkey  lpermno  lpermco   datadate   fyear    tic      cusip  \\\n",
       "0       001038  66413.0   6301.0 1989-03-31  1988.0  AEN.2  001669100   \n",
       "1       001038  66413.0   6301.0 1990-03-31  1989.0  AEN.2  001669100   \n",
       "2       001038  66413.0   6301.0 1991-03-31  1990.0  AEN.2  001669100   \n",
       "3       001038  66413.0   6301.0 1992-03-31  1991.0  AEN.2  001669100   \n",
       "4       001038  66413.0   6301.0 1993-03-31  1992.0  AEN.2  001669100   \n",
       "...        ...      ...      ...        ...     ...    ...        ...   \n",
       "204988  066336  89498.0  43502.0 2005-12-31  2005.0   TSBA  89157H106   \n",
       "204989  066336  89498.0  43502.0 2006-12-31  2006.0   TSBA  89157H106   \n",
       "204990  066336  89498.0  43502.0 2007-12-31  2007.0   TSBA  89157H106   \n",
       "204991  066336  89498.0  43502.0 2008-12-31  2008.0   TSBA  89157H106   \n",
       "204992  176828  18459.0  56685.0 2019-12-31  2019.0   CARE  146103106   \n",
       "\n",
       "                              conm         cik    sich   sic  datayear  \n",
       "0       AMC ENTERTAINMENT INC -OLD              7830.0  7830      1989  \n",
       "1       AMC ENTERTAINMENT INC -OLD              7830.0  7830      1990  \n",
       "2       AMC ENTERTAINMENT INC -OLD              7830.0  7830      1991  \n",
       "3       AMC ENTERTAINMENT INC -OLD              7830.0  7830      1992  \n",
       "4       AMC ENTERTAINMENT INC -OLD              7830.0  7830      1993  \n",
       "...                            ...         ...     ...   ...       ...  \n",
       "204988   TOUCHSTONE BANKSHARES INC  0001821297  6020.0  6020      2005  \n",
       "204989   TOUCHSTONE BANKSHARES INC  0001821297  6020.0  6020      2006  \n",
       "204990   TOUCHSTONE BANKSHARES INC  0001821297  6020.0  6020      2007  \n",
       "204991   TOUCHSTONE BANKSHARES INC  0001821297  6020.0  6020      2008  \n",
       "204992       CARTER BANKSHARES INC  0001829576  6020.0  6020      2019  \n",
       "\n",
       "[204993 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204993"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5922\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sorted_database)):\n",
    "    if len(sorted_database['cik'][i])!=0:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDict = {}\n",
    "for i in range(5922,len(sorted_database)):\n",
    "    #storing this first CIK as previous CIK\n",
    "    prev = sorted_database['cik'][i]\n",
    "    #creating empty list for datadates over 1989-2021 period\n",
    "    l = [None] * 33\n",
    "    while i<len(sorted_database) and sorted_database['cik'][i] == prev:\n",
    "        year = sorted_database['datayear'][i]\n",
    "        sample_year = year\n",
    "        l[year-1989] = sorted_database['datadate'][i]\n",
    "        sample_datadate = sorted_database['datadate'][i]\n",
    "        i += 1\n",
    "        for j in range(len(l)):\n",
    "            if l[j] == None:\n",
    "                yr = j + 1989\n",
    "                mnth = sample_datadate.month\n",
    "                dy = sample_datadate.day\n",
    "                # Create the Timestamp object\n",
    "                ts = pd.Timestamp(year = yr, month = mnth, day = dy - 1, hour = 0, minute = 0, second = 0)\n",
    "                l[j] = ts\n",
    "    myDict[prev] = l\n",
    "    i -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19511"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(myDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('1989-12-30 00:00:00'),\n",
       " Timestamp('1990-12-30 00:00:00'),\n",
       " Timestamp('1991-12-30 00:00:00'),\n",
       " Timestamp('1992-12-30 00:00:00'),\n",
       " Timestamp('1993-12-30 00:00:00'),\n",
       " Timestamp('1994-12-30 00:00:00'),\n",
       " Timestamp('1995-12-30 00:00:00'),\n",
       " Timestamp('1996-12-30 00:00:00'),\n",
       " Timestamp('1997-12-30 00:00:00'),\n",
       " Timestamp('1998-12-30 00:00:00'),\n",
       " Timestamp('1999-12-30 00:00:00'),\n",
       " Timestamp('2000-12-30 00:00:00'),\n",
       " Timestamp('2001-12-30 00:00:00'),\n",
       " Timestamp('2002-12-30 00:00:00'),\n",
       " Timestamp('2003-12-30 00:00:00'),\n",
       " Timestamp('2004-12-30 00:00:00'),\n",
       " Timestamp('2005-12-30 00:00:00'),\n",
       " Timestamp('2006-12-30 00:00:00'),\n",
       " Timestamp('2007-12-30 00:00:00'),\n",
       " Timestamp('2008-12-31 00:00:00'),\n",
       " Timestamp('2009-12-30 00:00:00'),\n",
       " Timestamp('2010-12-30 00:00:00'),\n",
       " Timestamp('2011-12-30 00:00:00'),\n",
       " Timestamp('2012-12-30 00:00:00'),\n",
       " Timestamp('2013-12-30 00:00:00'),\n",
       " Timestamp('2014-12-30 00:00:00'),\n",
       " Timestamp('2015-12-30 00:00:00'),\n",
       " Timestamp('2016-12-30 00:00:00'),\n",
       " Timestamp('2017-12-30 00:00:00'),\n",
       " Timestamp('2018-12-30 00:00:00'),\n",
       " Timestamp('2019-12-30 00:00:00'),\n",
       " Timestamp('2020-12-30 00:00:00'),\n",
       " Timestamp('2021-12-30 00:00:00')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDict['0001821297']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv',encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229956"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(inplace= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229741"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df) #checking how many unique are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Field1</th>\n",
       "      <th>Field2_Text</th>\n",
       "      <th>Field3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...</td>\n",
       "      <td>Jun.  1, 2020  2:30 PM ET</td>\n",
       "      <td>EOG Resources, Inc. (EOG)</td>\n",
       "      <td>EOG Resources, Inc. (NYSE:EOG) AllianceBernste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...</td>\n",
       "      <td>May 20, 2020  5:35 PM ET</td>\n",
       "      <td>Eaton Vance Corp. (EV)</td>\n",
       "      <td>Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...</td>\n",
       "      <td>May  8, 2020  5:25 PM ET</td>\n",
       "      <td>Whitestone REIT (WSR)</td>\n",
       "      <td>Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Applied Materials Inc (AMAT) CEO Gary Dickerso...</td>\n",
       "      <td>May 30, 2020  1:22 AM ET</td>\n",
       "      <td>Applied Materials, Inc. (AMAT)</td>\n",
       "      <td>Applied Materials Inc (NASDAQ:AMAT)  2020 Bern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Garrett Motion Inc. (GTX) CEO Olivier Rabiller...</td>\n",
       "      <td>May 11, 2020  5:16 PM ET</td>\n",
       "      <td>Garrett Motion Inc. (GTX)</td>\n",
       "      <td>Start Time: 08:30 January  1, 0000  9:26 AM ET...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229736</th>\n",
       "      <td>Memorial Resource Development's (MRD) CEO John...</td>\n",
       "      <td>May  6, 2015  9:50 PM ET</td>\n",
       "      <td>Memorial Resource Development Corp. (MRD)</td>\n",
       "      <td>Memorial Resource Development Corp (NASDAQ:MRD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229737</th>\n",
       "      <td>Intersect ENT's (XENT) CEO Lisa Earnhardt on Q...</td>\n",
       "      <td>May  6, 2015  9:48 PM ET</td>\n",
       "      <td>Intersect ENT, Inc. (XENT)</td>\n",
       "      <td>Intersect ENT, Inc. (NASDAQ:XENT) Q1 2015 Earn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229738</th>\n",
       "      <td>Paycom Software's (PAYC) CEO Chad Richison on ...</td>\n",
       "      <td>May  6, 2015  9:46 PM ET</td>\n",
       "      <td>Paycom Software, Inc. (PAYC)</td>\n",
       "      <td>Paycom Software Inc. (NYSE:PAYC) Q1 2015 Earni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229739</th>\n",
       "      <td>Cerulean Pharma's (CERU) CEO Chris Guiffre Dis...</td>\n",
       "      <td>May  6, 2015  9:46 PM ET</td>\n",
       "      <td>DarÃƒÂ© Bioscience, Inc. (DARE)</td>\n",
       "      <td>Cerulean Pharma Inc. (CERU) Q1 2015 Earnings C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229740</th>\n",
       "      <td>Powell Industries' (POWL) CEO Mike Lucas on Q2...</td>\n",
       "      <td>May  6, 2015  9:37 PM ET</td>\n",
       "      <td>Powell Industries, Inc. (POWL)</td>\n",
       "      <td>Powell Industries, Inc. (NASDAQ:POWL) Q2 2015 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229741 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  \\\n",
       "0       EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...   \n",
       "1       Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...   \n",
       "2       Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...   \n",
       "3       Applied Materials Inc (AMAT) CEO Gary Dickerso...   \n",
       "4       Garrett Motion Inc. (GTX) CEO Olivier Rabiller...   \n",
       "...                                                   ...   \n",
       "229736  Memorial Resource Development's (MRD) CEO John...   \n",
       "229737  Intersect ENT's (XENT) CEO Lisa Earnhardt on Q...   \n",
       "229738  Paycom Software's (PAYC) CEO Chad Richison on ...   \n",
       "229739  Cerulean Pharma's (CERU) CEO Chris Guiffre Dis...   \n",
       "229740  Powell Industries' (POWL) CEO Mike Lucas on Q2...   \n",
       "\n",
       "                           Field1                                Field2_Text  \\\n",
       "0       Jun.  1, 2020  2:30 PM ET                  EOG Resources, Inc. (EOG)   \n",
       "1        May 20, 2020  5:35 PM ET                     Eaton Vance Corp. (EV)   \n",
       "2        May  8, 2020  5:25 PM ET                      Whitestone REIT (WSR)   \n",
       "3        May 30, 2020  1:22 AM ET             Applied Materials, Inc. (AMAT)   \n",
       "4        May 11, 2020  5:16 PM ET                  Garrett Motion Inc. (GTX)   \n",
       "...                           ...                                        ...   \n",
       "229736   May  6, 2015  9:50 PM ET  Memorial Resource Development Corp. (MRD)   \n",
       "229737   May  6, 2015  9:48 PM ET                 Intersect ENT, Inc. (XENT)   \n",
       "229738   May  6, 2015  9:46 PM ET               Paycom Software, Inc. (PAYC)   \n",
       "229739   May  6, 2015  9:46 PM ET              DarÃƒÂ© Bioscience, Inc. (DARE)   \n",
       "229740   May  6, 2015  9:37 PM ET             Powell Industries, Inc. (POWL)   \n",
       "\n",
       "                                                   Field3  \n",
       "0       EOG Resources, Inc. (NYSE:EOG) AllianceBernste...  \n",
       "1       Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...  \n",
       "2       Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...  \n",
       "3       Applied Materials Inc (NASDAQ:AMAT)  2020 Bern...  \n",
       "4       Start Time: 08:30 January  1, 0000  9:26 AM ET...  \n",
       "...                                                   ...  \n",
       "229736  Memorial Resource Development Corp (NASDAQ:MRD...  \n",
       "229737  Intersect ENT, Inc. (NASDAQ:XENT) Q1 2015 Earn...  \n",
       "229738  Paycom Software Inc. (NYSE:PAYC) Q1 2015 Earni...  \n",
       "229739  Cerulean Pharma Inc. (CERU) Q1 2015 Earnings C...  \n",
       "229740  Powell Industries, Inc. (NASDAQ:POWL) Q2 2015 ...  \n",
       "\n",
       "[229741 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_name = df['Field2_Text']    # creating a list of company names and their tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting tickers\n",
    "tickers = []\n",
    "Deleted_i = []\n",
    "for i in range(229741):\n",
    "    try:\n",
    "        ticker = com_name[i][com_name[i].find(\"(\")+1:com_name[i].find(\")\")]\n",
    "    except:\n",
    "        Deleted_i.append(i)\n",
    "    tickers.append(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tickers'] = tickers         # creating a new column in dataframe of only tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tickers'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating company names like we did for tickers\n",
    "com_names = []\n",
    "del_i = []\n",
    "for i in range(len(com_name)):\n",
    "    try:\n",
    "        name = com_name[i][0:com_name[i].find(\"(\")-1]\n",
    "    except:\n",
    "        del_i.append(i)\n",
    "    com_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['company_names_seekingalpha'] = com_names #creating a new column of company names from seeking alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cikandticker = database[['cik', 'tic']] #creating a subdataframe of only company name and tickers\n",
    "#here tickers are the link between the company names from seeking alpha and company names from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = database[['cik', 'tic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204993"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cikandticker.drop_duplicates(inplace = True) #deduplication of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>tic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000730052</td>\n",
       "      <td>ANTQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>AIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0000313368</td>\n",
       "      <td>ABSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0000702511</td>\n",
       "      <td>ACSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0000002134</td>\n",
       "      <td>6927B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204986</th>\n",
       "      <td>0001707210</td>\n",
       "      <td>NMCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204988</th>\n",
       "      <td>0001739445</td>\n",
       "      <td>ACA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204990</th>\n",
       "      <td>0001720161</td>\n",
       "      <td>CTRM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204991</th>\n",
       "      <td>0001280776</td>\n",
       "      <td>IMUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204992</th>\n",
       "      <td>0000921114</td>\n",
       "      <td>ARMP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20518 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               cik    tic\n",
       "0       0000730052   ANTQ\n",
       "1       0000001750    AIR\n",
       "32      0000313368   ABSI\n",
       "38      0000702511   ACSE\n",
       "44      0000002134  6927B\n",
       "...            ...    ...\n",
       "204986  0001707210   NMCI\n",
       "204988  0001739445    ACA\n",
       "204990  0001720161   CTRM\n",
       "204991  0001280776   IMUX\n",
       "204992  0000921114   ARMP\n",
       "\n",
       "[20518 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cikandticker[['cik','tic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting company names from the database which have the same ticker as that of our original data from seeking alpha\n",
    "ciks = []\n",
    "for ticker in tickers:\n",
    "    cik = cikandticker.loc[cikandticker['tic'] == ticker, 'cik']\n",
    "    #print(company)\n",
    "    try: #using try and except to avoid any errors when the company name is missing due to some missing values in data\n",
    "        ciks.append(cik.iloc[0])\n",
    "    except:\n",
    "        ciks.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CIK'] = ciks #creating a new column of the company names from database to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "conameandticker = database[['conm', 'tic']] #creating a subdataframe of only company name and tickers\n",
    "#here tickers are the link between the company names from seeking alpha and company names from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "conameandticker.drop_duplicates(inplace = True) #deduplication of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conm</th>\n",
       "      <th>tic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.A. IMPORTING CO INC</td>\n",
       "      <td>ANTQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>AIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ABS INDUSTRIES INC</td>\n",
       "      <td>ABSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ACS ENTERPRISES INC</td>\n",
       "      <td>ACSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ACS INDUSTRIES INC</td>\n",
       "      <td>6927B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204986</th>\n",
       "      <td>NAVIOS MARITIME CONTAINERS</td>\n",
       "      <td>NMCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204988</th>\n",
       "      <td>ARCOSA INC</td>\n",
       "      <td>ACA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204990</th>\n",
       "      <td>CASTOR MARITIME INC</td>\n",
       "      <td>CTRM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204991</th>\n",
       "      <td>IMMUNIC INC</td>\n",
       "      <td>IMUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204992</th>\n",
       "      <td>ARMATA PHARMACEUTICALS INC</td>\n",
       "      <td>ARMP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20518 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              conm    tic\n",
       "0            A.A. IMPORTING CO INC   ANTQ\n",
       "1                         AAR CORP    AIR\n",
       "32              ABS INDUSTRIES INC   ABSI\n",
       "38             ACS ENTERPRISES INC   ACSE\n",
       "44              ACS INDUSTRIES INC  6927B\n",
       "...                            ...    ...\n",
       "204986  NAVIOS MARITIME CONTAINERS   NMCI\n",
       "204988                  ARCOSA INC    ACA\n",
       "204990         CASTOR MARITIME INC   CTRM\n",
       "204991                 IMMUNIC INC   IMUX\n",
       "204992  ARMATA PHARMACEUTICALS INC   ARMP\n",
       "\n",
       "[20518 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conameandticker[['conm','tic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting company names from the database which have the same ticker as that of our original data from seeking alpha\n",
    "companies = []\n",
    "for ticker in tickers:\n",
    "    company = conameandticker.loc[conameandticker['tic'] == ticker, 'conm']\n",
    "    #print(company)\n",
    "    try: #using try and except to avoid any errors when the company name is missing due to some missing values in data\n",
    "        companies.append(company.iloc[0])\n",
    "    except:\n",
    "        companies.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['company_names_database'] = companies #creating a new column of the company names from database to compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge python-levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "#if warning comes then use the below command in Anaconda Prompt\n",
    "#conda install -c conda-forge python-levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the scores after fuzzy matching between company names from two sources i.e seeking alpha and database\n",
    "scores = []\n",
    "for i,j in zip(df.company_names_seekingalpha,df.company_names_database):\n",
    "    score = fuzz.token_set_ratio(i,j)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['similarity_scores'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "dates = []\n",
    "months = []\n",
    "for i in range(len(df)):\n",
    "    datetime = df['Field1'][i]\n",
    "    month = datetime[0:3].strip()\n",
    "    idx = datetime.find(',')\n",
    "    date = datetime[4:idx].strip()\n",
    "    year = datetime[idx+1:idx+6].strip()\n",
    "    years.append(year)\n",
    "    months.append(month)\n",
    "    dates.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year'] = years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Month'] = months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Day'] = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toint(month):\n",
    "    if month == \"Jan\":\n",
    "        return 1\n",
    "    elif month == \"Feb\":\n",
    "        return 2\n",
    "    elif month == \"Mar\":\n",
    "        return 3\n",
    "    elif month == \"Apr\":\n",
    "        return 4\n",
    "    elif month == \"May\":\n",
    "        return 5\n",
    "    elif month == \"Jun\":\n",
    "        return 6\n",
    "    elif month == \"Jul\":\n",
    "        return 7\n",
    "    elif month == \"Aug\":\n",
    "        return 8\n",
    "    elif month == \"Sep\":\n",
    "        return 9\n",
    "    elif month == \"Oct\":\n",
    "        return 10\n",
    "    elif month == \"Nov\":\n",
    "        return 11\n",
    "    else:\n",
    "        return 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "calldict = {}\n",
    "nonevalues = []\n",
    "for i in range(len(df)):\n",
    "    cik = df['CIK'][i]\n",
    "    if cik==None:\n",
    "        continue\n",
    "    year = int(df['Year'][i])\n",
    "    try:\n",
    "        timestamp = myDict[cik][year-1989]\n",
    "        datadate = timestamp.day\n",
    "        datamonth = timestamp.month\n",
    "        calldate = int(df['Day'][i])\n",
    "        callmonth = toint(df['Month'][i])\n",
    "        yr = year\n",
    "        if callmonth < datamonth:\n",
    "            yr = year - 1\n",
    "        elif callmonth > datamonth:\n",
    "            yr = year\n",
    "        elif callmonth == datamonth:\n",
    "            if calldate <= datadate:\n",
    "                yr = year - 1\n",
    "            else:\n",
    "                yr = year\n",
    "        if cik in calldict.keys():\n",
    "            calldict[cik][yr-1989] += 1\n",
    "        else:\n",
    "            l = [0]*33\n",
    "            l[yr-1989] += 1\n",
    "            calldict[cik] = l\n",
    "    except:\n",
    "        nonevalues.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229740"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5837"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(calldict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "concalldata = pd.DataFrame.from_dict(calldict, orient ='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000821189</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000350797</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001175535</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000006951</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001617406</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000754009</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001007019</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001505823</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001448301</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001063259</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5837 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0   1   2   3   4   5   6   7   8   9   ...  23  24  25  26  27  \\\n",
       "0000821189   0   0   0   0   0   0   0   0   0   0  ...  12   5  10   6   6   \n",
       "0000350797   0   0   0   0   0   0   0   0   0   0  ...   6   5   6   7   6   \n",
       "0001175535   0   0   0   0   0   0   0   0   0   0  ...   4   4   6   6   6   \n",
       "0000006951   0   0   0   0   0   0   0   0   0   0  ...   9  11   5   7   6   \n",
       "0001617406   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   5   \n",
       "...         ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..   \n",
       "0000754009   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "0001007019   0   0   0   0   0   0   0   0   0   0  ...   0   0   1   0   0   \n",
       "0001505823   0   0   0   0   0   0   0   0   0   0  ...   0   0   1   0   0   \n",
       "0001448301   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   1   0   \n",
       "0001063259   0   0   0   0   0   0   0   0   0   0  ...   0   0   1   0   0   \n",
       "\n",
       "            28  29  30  31  32  \n",
       "0000821189  11  13  10   0   0  \n",
       "0000350797   7   8   6   0   0  \n",
       "0001175535   7   8   5   0   0  \n",
       "0000006951  10   9  15   0   0  \n",
       "0001617406   7   8   5   0   0  \n",
       "...         ..  ..  ..  ..  ..  \n",
       "0000754009   0   0   0   0   0  \n",
       "0001007019   0   0   0   0   0  \n",
       "0001505823   0   0   0   0   0  \n",
       "0001448301   0   0   0   0   0  \n",
       "0001063259   0   0   0   0   0  \n",
       "\n",
       "[5837 rows x 33 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concalldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nonevalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Field1</th>\n",
       "      <th>Field2_Text</th>\n",
       "      <th>Field3</th>\n",
       "      <th>tickers</th>\n",
       "      <th>company_names_seekingalpha</th>\n",
       "      <th>CIK</th>\n",
       "      <th>company_names_database</th>\n",
       "      <th>similarity_scores</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...</td>\n",
       "      <td>Jun.  1, 2020  2:30 PM ET</td>\n",
       "      <td>EOG Resources, Inc. (EOG)</td>\n",
       "      <td>EOG Resources, Inc. (NYSE:EOG) AllianceBernste...</td>\n",
       "      <td>EOG</td>\n",
       "      <td>EOG Resources, Inc.</td>\n",
       "      <td>0000821189</td>\n",
       "      <td>EOG RESOURCES INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jun</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...</td>\n",
       "      <td>May 20, 2020  5:35 PM ET</td>\n",
       "      <td>Eaton Vance Corp. (EV)</td>\n",
       "      <td>Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...</td>\n",
       "      <td>EV</td>\n",
       "      <td>Eaton Vance Corp.</td>\n",
       "      <td>0000350797</td>\n",
       "      <td>EATON VANCE CORP</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...</td>\n",
       "      <td>May  8, 2020  5:25 PM ET</td>\n",
       "      <td>Whitestone REIT (WSR)</td>\n",
       "      <td>Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...</td>\n",
       "      <td>WSR</td>\n",
       "      <td>Whitestone REIT</td>\n",
       "      <td>0001175535</td>\n",
       "      <td>WHITESTONE REIT</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Applied Materials Inc (AMAT) CEO Gary Dickerso...</td>\n",
       "      <td>May 30, 2020  1:22 AM ET</td>\n",
       "      <td>Applied Materials, Inc. (AMAT)</td>\n",
       "      <td>Applied Materials Inc (NASDAQ:AMAT)  2020 Bern...</td>\n",
       "      <td>AMAT</td>\n",
       "      <td>Applied Materials, Inc.</td>\n",
       "      <td>0000006951</td>\n",
       "      <td>APPLIED MATERIALS INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Garrett Motion Inc. (GTX) CEO Olivier Rabiller...</td>\n",
       "      <td>May 11, 2020  5:16 PM ET</td>\n",
       "      <td>Garrett Motion Inc. (GTX)</td>\n",
       "      <td>Start Time: 08:30 January  1, 0000  9:26 AM ET...</td>\n",
       "      <td>GTX</td>\n",
       "      <td>Garrett Motion Inc.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...   \n",
       "1  Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...   \n",
       "2  Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...   \n",
       "3  Applied Materials Inc (AMAT) CEO Gary Dickerso...   \n",
       "4  Garrett Motion Inc. (GTX) CEO Olivier Rabiller...   \n",
       "\n",
       "                      Field1                     Field2_Text  \\\n",
       "0  Jun.  1, 2020  2:30 PM ET       EOG Resources, Inc. (EOG)   \n",
       "1   May 20, 2020  5:35 PM ET          Eaton Vance Corp. (EV)   \n",
       "2   May  8, 2020  5:25 PM ET           Whitestone REIT (WSR)   \n",
       "3   May 30, 2020  1:22 AM ET  Applied Materials, Inc. (AMAT)   \n",
       "4   May 11, 2020  5:16 PM ET       Garrett Motion Inc. (GTX)   \n",
       "\n",
       "                                              Field3 tickers  \\\n",
       "0  EOG Resources, Inc. (NYSE:EOG) AllianceBernste...     EOG   \n",
       "1  Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...      EV   \n",
       "2  Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...     WSR   \n",
       "3  Applied Materials Inc (NASDAQ:AMAT)  2020 Bern...    AMAT   \n",
       "4  Start Time: 08:30 January  1, 0000  9:26 AM ET...     GTX   \n",
       "\n",
       "  company_names_seekingalpha         CIK company_names_database  \\\n",
       "0        EOG Resources, Inc.  0000821189      EOG RESOURCES INC   \n",
       "1          Eaton Vance Corp.  0000350797       EATON VANCE CORP   \n",
       "2            Whitestone REIT  0001175535        WHITESTONE REIT   \n",
       "3    Applied Materials, Inc.  0000006951  APPLIED MATERIALS INC   \n",
       "4        Garrett Motion Inc.        None                   None   \n",
       "\n",
       "   similarity_scores  Year Month Day  \n",
       "0                100  2020   Jun   1  \n",
       "1                100  2020   May  20  \n",
       "2                100  2020   May   8  \n",
       "3                100  2020   May  30  \n",
       "4                  0  2020   May  11  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229741"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Field1</th>\n",
       "      <th>Field2_Text</th>\n",
       "      <th>Field3</th>\n",
       "      <th>tickers</th>\n",
       "      <th>company_names_seekingalpha</th>\n",
       "      <th>CIK</th>\n",
       "      <th>company_names_database</th>\n",
       "      <th>similarity_scores</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...</td>\n",
       "      <td>Jun.  1, 2020  2:30 PM ET</td>\n",
       "      <td>EOG Resources, Inc. (EOG)</td>\n",
       "      <td>EOG Resources, Inc. (NYSE:EOG) AllianceBernste...</td>\n",
       "      <td>EOG</td>\n",
       "      <td>EOG Resources, Inc.</td>\n",
       "      <td>0000821189</td>\n",
       "      <td>EOG RESOURCES INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jun</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...</td>\n",
       "      <td>May 20, 2020  5:35 PM ET</td>\n",
       "      <td>Eaton Vance Corp. (EV)</td>\n",
       "      <td>Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...</td>\n",
       "      <td>EV</td>\n",
       "      <td>Eaton Vance Corp.</td>\n",
       "      <td>0000350797</td>\n",
       "      <td>EATON VANCE CORP</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...</td>\n",
       "      <td>May  8, 2020  5:25 PM ET</td>\n",
       "      <td>Whitestone REIT (WSR)</td>\n",
       "      <td>Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...</td>\n",
       "      <td>WSR</td>\n",
       "      <td>Whitestone REIT</td>\n",
       "      <td>0001175535</td>\n",
       "      <td>WHITESTONE REIT</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Applied Materials Inc (AMAT) CEO Gary Dickerso...</td>\n",
       "      <td>May 30, 2020  1:22 AM ET</td>\n",
       "      <td>Applied Materials, Inc. (AMAT)</td>\n",
       "      <td>Applied Materials Inc (NASDAQ:AMAT)  2020 Bern...</td>\n",
       "      <td>AMAT</td>\n",
       "      <td>Applied Materials, Inc.</td>\n",
       "      <td>0000006951</td>\n",
       "      <td>APPLIED MATERIALS INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Garrett Motion Inc. (GTX) CEO Olivier Rabiller...</td>\n",
       "      <td>May 11, 2020  5:16 PM ET</td>\n",
       "      <td>Garrett Motion Inc. (GTX)</td>\n",
       "      <td>Start Time: 08:30 January  1, 0000  9:26 AM ET...</td>\n",
       "      <td>GTX</td>\n",
       "      <td>Garrett Motion Inc.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229736</th>\n",
       "      <td>Memorial Resource Development's (MRD) CEO John...</td>\n",
       "      <td>May  6, 2015  9:50 PM ET</td>\n",
       "      <td>Memorial Resource Development Corp. (MRD)</td>\n",
       "      <td>Memorial Resource Development Corp (NASDAQ:MRD...</td>\n",
       "      <td>MRD</td>\n",
       "      <td>Memorial Resource Development Corp.</td>\n",
       "      <td>0001599222</td>\n",
       "      <td>MEMORIAL RESOURCE DEV CORP</td>\n",
       "      <td>92</td>\n",
       "      <td>2015</td>\n",
       "      <td>May</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229737</th>\n",
       "      <td>Intersect ENT's (XENT) CEO Lisa Earnhardt on Q...</td>\n",
       "      <td>May  6, 2015  9:48 PM ET</td>\n",
       "      <td>Intersect ENT, Inc. (XENT)</td>\n",
       "      <td>Intersect ENT, Inc. (NASDAQ:XENT) Q1 2015 Earn...</td>\n",
       "      <td>XENT</td>\n",
       "      <td>Intersect ENT, Inc.</td>\n",
       "      <td>0001271214</td>\n",
       "      <td>INTERSECT ENT INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2015</td>\n",
       "      <td>May</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229738</th>\n",
       "      <td>Paycom Software's (PAYC) CEO Chad Richison on ...</td>\n",
       "      <td>May  6, 2015  9:46 PM ET</td>\n",
       "      <td>Paycom Software, Inc. (PAYC)</td>\n",
       "      <td>Paycom Software Inc. (NYSE:PAYC) Q1 2015 Earni...</td>\n",
       "      <td>PAYC</td>\n",
       "      <td>Paycom Software, Inc.</td>\n",
       "      <td>0001590955</td>\n",
       "      <td>PAYCOM SOFTWARE INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2015</td>\n",
       "      <td>May</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229739</th>\n",
       "      <td>Cerulean Pharma's (CERU) CEO Chris Guiffre Dis...</td>\n",
       "      <td>May  6, 2015  9:46 PM ET</td>\n",
       "      <td>DarÃƒÂ© Bioscience, Inc. (DARE)</td>\n",
       "      <td>Cerulean Pharma Inc. (CERU) Q1 2015 Earnings C...</td>\n",
       "      <td>DARE</td>\n",
       "      <td>DarÃƒÂ© Bioscience, Inc.</td>\n",
       "      <td>0001701808</td>\n",
       "      <td>DARE BIOSCIENCE INC</td>\n",
       "      <td>97</td>\n",
       "      <td>2015</td>\n",
       "      <td>May</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229740</th>\n",
       "      <td>Powell Industries' (POWL) CEO Mike Lucas on Q2...</td>\n",
       "      <td>May  6, 2015  9:37 PM ET</td>\n",
       "      <td>Powell Industries, Inc. (POWL)</td>\n",
       "      <td>Powell Industries, Inc. (NASDAQ:POWL) Q2 2015 ...</td>\n",
       "      <td>POWL</td>\n",
       "      <td>Powell Industries, Inc.</td>\n",
       "      <td>0000080420</td>\n",
       "      <td>POWELL INDUSTRIES INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2015</td>\n",
       "      <td>May</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229741 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  \\\n",
       "0       EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...   \n",
       "1       Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...   \n",
       "2       Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...   \n",
       "3       Applied Materials Inc (AMAT) CEO Gary Dickerso...   \n",
       "4       Garrett Motion Inc. (GTX) CEO Olivier Rabiller...   \n",
       "...                                                   ...   \n",
       "229736  Memorial Resource Development's (MRD) CEO John...   \n",
       "229737  Intersect ENT's (XENT) CEO Lisa Earnhardt on Q...   \n",
       "229738  Paycom Software's (PAYC) CEO Chad Richison on ...   \n",
       "229739  Cerulean Pharma's (CERU) CEO Chris Guiffre Dis...   \n",
       "229740  Powell Industries' (POWL) CEO Mike Lucas on Q2...   \n",
       "\n",
       "                           Field1                                Field2_Text  \\\n",
       "0       Jun.  1, 2020  2:30 PM ET                  EOG Resources, Inc. (EOG)   \n",
       "1        May 20, 2020  5:35 PM ET                     Eaton Vance Corp. (EV)   \n",
       "2        May  8, 2020  5:25 PM ET                      Whitestone REIT (WSR)   \n",
       "3        May 30, 2020  1:22 AM ET             Applied Materials, Inc. (AMAT)   \n",
       "4        May 11, 2020  5:16 PM ET                  Garrett Motion Inc. (GTX)   \n",
       "...                           ...                                        ...   \n",
       "229736   May  6, 2015  9:50 PM ET  Memorial Resource Development Corp. (MRD)   \n",
       "229737   May  6, 2015  9:48 PM ET                 Intersect ENT, Inc. (XENT)   \n",
       "229738   May  6, 2015  9:46 PM ET               Paycom Software, Inc. (PAYC)   \n",
       "229739   May  6, 2015  9:46 PM ET              DarÃƒÂ© Bioscience, Inc. (DARE)   \n",
       "229740   May  6, 2015  9:37 PM ET             Powell Industries, Inc. (POWL)   \n",
       "\n",
       "                                                   Field3 tickers  \\\n",
       "0       EOG Resources, Inc. (NYSE:EOG) AllianceBernste...     EOG   \n",
       "1       Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...      EV   \n",
       "2       Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...     WSR   \n",
       "3       Applied Materials Inc (NASDAQ:AMAT)  2020 Bern...    AMAT   \n",
       "4       Start Time: 08:30 January  1, 0000  9:26 AM ET...     GTX   \n",
       "...                                                   ...     ...   \n",
       "229736  Memorial Resource Development Corp (NASDAQ:MRD...     MRD   \n",
       "229737  Intersect ENT, Inc. (NASDAQ:XENT) Q1 2015 Earn...    XENT   \n",
       "229738  Paycom Software Inc. (NYSE:PAYC) Q1 2015 Earni...    PAYC   \n",
       "229739  Cerulean Pharma Inc. (CERU) Q1 2015 Earnings C...    DARE   \n",
       "229740  Powell Industries, Inc. (NASDAQ:POWL) Q2 2015 ...    POWL   \n",
       "\n",
       "                 company_names_seekingalpha         CIK  \\\n",
       "0                       EOG Resources, Inc.  0000821189   \n",
       "1                         Eaton Vance Corp.  0000350797   \n",
       "2                           Whitestone REIT  0001175535   \n",
       "3                   Applied Materials, Inc.  0000006951   \n",
       "4                       Garrett Motion Inc.        None   \n",
       "...                                     ...         ...   \n",
       "229736  Memorial Resource Development Corp.  0001599222   \n",
       "229737                  Intersect ENT, Inc.  0001271214   \n",
       "229738                Paycom Software, Inc.  0001590955   \n",
       "229739               DarÃƒÂ© Bioscience, Inc.  0001701808   \n",
       "229740              Powell Industries, Inc.  0000080420   \n",
       "\n",
       "            company_names_database  similarity_scores  Year Month Day  \n",
       "0                EOG RESOURCES INC                100  2020   Jun   1  \n",
       "1                 EATON VANCE CORP                100  2020   May  20  \n",
       "2                  WHITESTONE REIT                100  2020   May   8  \n",
       "3            APPLIED MATERIALS INC                100  2020   May  30  \n",
       "4                             None                  0  2020   May  11  \n",
       "...                            ...                ...   ...   ...  ..  \n",
       "229736  MEMORIAL RESOURCE DEV CORP                 92  2015   May   6  \n",
       "229737           INTERSECT ENT INC                100  2015   May   6  \n",
       "229738         PAYCOM SOFTWARE INC                100  2015   May   6  \n",
       "229739         DARE BIOSCIENCE INC                 97  2015   May   6  \n",
       "229740       POWELL INDUSTRIES INC                100  2015   May   6  \n",
       "\n",
       "[229741 rows x 12 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('1989-12-30 00:00:00'),\n",
       " Timestamp('1990-12-30 00:00:00'),\n",
       " Timestamp('1991-12-30 00:00:00'),\n",
       " Timestamp('1992-12-30 00:00:00'),\n",
       " Timestamp('1993-12-30 00:00:00'),\n",
       " Timestamp('1994-12-30 00:00:00'),\n",
       " Timestamp('1995-12-30 00:00:00'),\n",
       " Timestamp('1996-12-30 00:00:00'),\n",
       " Timestamp('1997-12-30 00:00:00'),\n",
       " Timestamp('1998-12-30 00:00:00'),\n",
       " Timestamp('1999-12-30 00:00:00'),\n",
       " Timestamp('2000-12-30 00:00:00'),\n",
       " Timestamp('2001-12-30 00:00:00'),\n",
       " Timestamp('2002-12-30 00:00:00'),\n",
       " Timestamp('2003-12-30 00:00:00'),\n",
       " Timestamp('2004-12-30 00:00:00'),\n",
       " Timestamp('2005-12-30 00:00:00'),\n",
       " Timestamp('2006-12-30 00:00:00'),\n",
       " Timestamp('2007-12-30 00:00:00'),\n",
       " Timestamp('2008-12-30 00:00:00'),\n",
       " Timestamp('2009-12-30 00:00:00'),\n",
       " Timestamp('2010-12-30 00:00:00'),\n",
       " Timestamp('2011-12-30 00:00:00'),\n",
       " Timestamp('2012-12-30 00:00:00'),\n",
       " Timestamp('2013-12-30 00:00:00'),\n",
       " Timestamp('2014-12-30 00:00:00'),\n",
       " Timestamp('2015-12-30 00:00:00'),\n",
       " Timestamp('2016-12-30 00:00:00'),\n",
       " Timestamp('2017-12-30 00:00:00'),\n",
       " Timestamp('2018-12-30 00:00:00'),\n",
       " Timestamp('2019-12-31 00:00:00'),\n",
       " Timestamp('2020-12-30 00:00:00'),\n",
       " Timestamp('2021-12-30 00:00:00')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDict['0000821189']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiscalyears = []\n",
    "nonevals = []\n",
    "for i in range(len(df)):\n",
    "    cik = df['CIK'][i]\n",
    "    if cik==None:\n",
    "        fiscalyears.append(None)\n",
    "        continue\n",
    "    year = int(df['Year'][i])\n",
    "    #print(year)\n",
    "    try:\n",
    "        timestamp = myDict[cik][year-1989]\n",
    "        datadate = timestamp.day\n",
    "        datamonth = timestamp.month\n",
    "        calldate = int(df['Day'][i])\n",
    "        callmonth = toint(df['Month'][i])\n",
    "        yr = year\n",
    "        if callmonth < datamonth:\n",
    "            yr = year - 1\n",
    "        elif callmonth > datamonth:\n",
    "            yr = year\n",
    "        elif callmonth == datamonth:\n",
    "            if calldate <= datadate:\n",
    "                yr = year - 1\n",
    "            else:\n",
    "                yr = year\n",
    "        fiscalyears.append(yr)\n",
    "    except:\n",
    "        fiscalyears.append(None)\n",
    "        nonevals.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229741"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fiscalyears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fyear'] = fiscalyears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Field1</th>\n",
       "      <th>Field2_Text</th>\n",
       "      <th>Field3</th>\n",
       "      <th>tickers</th>\n",
       "      <th>company_names_seekingalpha</th>\n",
       "      <th>CIK</th>\n",
       "      <th>company_names_database</th>\n",
       "      <th>similarity_scores</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>fyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...</td>\n",
       "      <td>Jun.  1, 2020  2:30 PM ET</td>\n",
       "      <td>EOG Resources, Inc. (EOG)</td>\n",
       "      <td>EOG Resources, Inc. (NYSE:EOG) AllianceBernste...</td>\n",
       "      <td>EOG</td>\n",
       "      <td>EOG Resources, Inc.</td>\n",
       "      <td>0000821189</td>\n",
       "      <td>EOG RESOURCES INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jun</td>\n",
       "      <td>1</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...</td>\n",
       "      <td>May 20, 2020  5:35 PM ET</td>\n",
       "      <td>Eaton Vance Corp. (EV)</td>\n",
       "      <td>Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...</td>\n",
       "      <td>EV</td>\n",
       "      <td>Eaton Vance Corp.</td>\n",
       "      <td>0000350797</td>\n",
       "      <td>EATON VANCE CORP</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>20</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...</td>\n",
       "      <td>May  8, 2020  5:25 PM ET</td>\n",
       "      <td>Whitestone REIT (WSR)</td>\n",
       "      <td>Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...</td>\n",
       "      <td>WSR</td>\n",
       "      <td>Whitestone REIT</td>\n",
       "      <td>0001175535</td>\n",
       "      <td>WHITESTONE REIT</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>8</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Applied Materials Inc (AMAT) CEO Gary Dickerso...</td>\n",
       "      <td>May 30, 2020  1:22 AM ET</td>\n",
       "      <td>Applied Materials, Inc. (AMAT)</td>\n",
       "      <td>Applied Materials Inc (NASDAQ:AMAT)  2020 Bern...</td>\n",
       "      <td>AMAT</td>\n",
       "      <td>Applied Materials, Inc.</td>\n",
       "      <td>0000006951</td>\n",
       "      <td>APPLIED MATERIALS INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>30</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Garrett Motion Inc. (GTX) CEO Olivier Rabiller...</td>\n",
       "      <td>May 11, 2020  5:16 PM ET</td>\n",
       "      <td>Garrett Motion Inc. (GTX)</td>\n",
       "      <td>Start Time: 08:30 January  1, 0000  9:26 AM ET...</td>\n",
       "      <td>GTX</td>\n",
       "      <td>Garrett Motion Inc.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...   \n",
       "1  Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...   \n",
       "2  Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...   \n",
       "3  Applied Materials Inc (AMAT) CEO Gary Dickerso...   \n",
       "4  Garrett Motion Inc. (GTX) CEO Olivier Rabiller...   \n",
       "\n",
       "                      Field1                     Field2_Text  \\\n",
       "0  Jun.  1, 2020  2:30 PM ET       EOG Resources, Inc. (EOG)   \n",
       "1   May 20, 2020  5:35 PM ET          Eaton Vance Corp. (EV)   \n",
       "2   May  8, 2020  5:25 PM ET           Whitestone REIT (WSR)   \n",
       "3   May 30, 2020  1:22 AM ET  Applied Materials, Inc. (AMAT)   \n",
       "4   May 11, 2020  5:16 PM ET       Garrett Motion Inc. (GTX)   \n",
       "\n",
       "                                              Field3 tickers  \\\n",
       "0  EOG Resources, Inc. (NYSE:EOG) AllianceBernste...     EOG   \n",
       "1  Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...      EV   \n",
       "2  Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...     WSR   \n",
       "3  Applied Materials Inc (NASDAQ:AMAT)  2020 Bern...    AMAT   \n",
       "4  Start Time: 08:30 January  1, 0000  9:26 AM ET...     GTX   \n",
       "\n",
       "  company_names_seekingalpha         CIK company_names_database  \\\n",
       "0        EOG Resources, Inc.  0000821189      EOG RESOURCES INC   \n",
       "1          Eaton Vance Corp.  0000350797       EATON VANCE CORP   \n",
       "2            Whitestone REIT  0001175535        WHITESTONE REIT   \n",
       "3    Applied Materials, Inc.  0000006951  APPLIED MATERIALS INC   \n",
       "4        Garrett Motion Inc.        None                   None   \n",
       "\n",
       "   similarity_scores  Year Month Day   fyear  \n",
       "0                100  2020   Jun   1  2019.0  \n",
       "1                100  2020   May  20  2019.0  \n",
       "2                100  2020   May   8  2019.0  \n",
       "3                100  2020   May  30  2019.0  \n",
       "4                  0  2020   May  11     NaN  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229741"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new1 = df.mask(df.eq('None')).dropna().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Field1</th>\n",
       "      <th>Field2_Text</th>\n",
       "      <th>Field3</th>\n",
       "      <th>tickers</th>\n",
       "      <th>company_names_seekingalpha</th>\n",
       "      <th>CIK</th>\n",
       "      <th>company_names_database</th>\n",
       "      <th>similarity_scores</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>fyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...</td>\n",
       "      <td>Jun.  1, 2020  2:30 PM ET</td>\n",
       "      <td>EOG Resources, Inc. (EOG)</td>\n",
       "      <td>EOG Resources, Inc. (NYSE:EOG) AllianceBernste...</td>\n",
       "      <td>EOG</td>\n",
       "      <td>EOG Resources, Inc.</td>\n",
       "      <td>0000821189</td>\n",
       "      <td>EOG RESOURCES INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jun</td>\n",
       "      <td>1</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...</td>\n",
       "      <td>May 20, 2020  5:35 PM ET</td>\n",
       "      <td>Eaton Vance Corp. (EV)</td>\n",
       "      <td>Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...</td>\n",
       "      <td>EV</td>\n",
       "      <td>Eaton Vance Corp.</td>\n",
       "      <td>0000350797</td>\n",
       "      <td>EATON VANCE CORP</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>20</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...</td>\n",
       "      <td>May  8, 2020  5:25 PM ET</td>\n",
       "      <td>Whitestone REIT (WSR)</td>\n",
       "      <td>Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...</td>\n",
       "      <td>WSR</td>\n",
       "      <td>Whitestone REIT</td>\n",
       "      <td>0001175535</td>\n",
       "      <td>WHITESTONE REIT</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>8</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Applied Materials Inc (AMAT) CEO Gary Dickerso...</td>\n",
       "      <td>May 30, 2020  1:22 AM ET</td>\n",
       "      <td>Applied Materials, Inc. (AMAT)</td>\n",
       "      <td>Applied Materials Inc (NASDAQ:AMAT)  2020 Bern...</td>\n",
       "      <td>AMAT</td>\n",
       "      <td>Applied Materials, Inc.</td>\n",
       "      <td>0000006951</td>\n",
       "      <td>APPLIED MATERIALS INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>30</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Park Hotels &amp; Resorts, Inc. (PK) CEO Thomas Ba...</td>\n",
       "      <td>May 11, 2020  5:10 PM ET</td>\n",
       "      <td>Park Hotels &amp; Resorts Inc. (PK)</td>\n",
       "      <td>Park Hotels &amp; Resorts, Inc. (NYSE:PK) Q1 2020 ...</td>\n",
       "      <td>PK</td>\n",
       "      <td>Park Hotels &amp; Resorts Inc.</td>\n",
       "      <td>0001617406</td>\n",
       "      <td>PARK HOTELS &amp; RESORTS</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>11</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...   \n",
       "1  Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...   \n",
       "2  Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...   \n",
       "3  Applied Materials Inc (AMAT) CEO Gary Dickerso...   \n",
       "4  Park Hotels & Resorts, Inc. (PK) CEO Thomas Ba...   \n",
       "\n",
       "                      Field1                      Field2_Text  \\\n",
       "0  Jun.  1, 2020  2:30 PM ET        EOG Resources, Inc. (EOG)   \n",
       "1   May 20, 2020  5:35 PM ET           Eaton Vance Corp. (EV)   \n",
       "2   May  8, 2020  5:25 PM ET            Whitestone REIT (WSR)   \n",
       "3   May 30, 2020  1:22 AM ET   Applied Materials, Inc. (AMAT)   \n",
       "4   May 11, 2020  5:10 PM ET  Park Hotels & Resorts Inc. (PK)   \n",
       "\n",
       "                                              Field3 tickers  \\\n",
       "0  EOG Resources, Inc. (NYSE:EOG) AllianceBernste...     EOG   \n",
       "1  Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...      EV   \n",
       "2  Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...     WSR   \n",
       "3  Applied Materials Inc (NASDAQ:AMAT)  2020 Bern...    AMAT   \n",
       "4  Park Hotels & Resorts, Inc. (NYSE:PK) Q1 2020 ...      PK   \n",
       "\n",
       "   company_names_seekingalpha         CIK company_names_database  \\\n",
       "0         EOG Resources, Inc.  0000821189      EOG RESOURCES INC   \n",
       "1           Eaton Vance Corp.  0000350797       EATON VANCE CORP   \n",
       "2             Whitestone REIT  0001175535        WHITESTONE REIT   \n",
       "3     Applied Materials, Inc.  0000006951  APPLIED MATERIALS INC   \n",
       "4  Park Hotels & Resorts Inc.  0001617406  PARK HOTELS & RESORTS   \n",
       "\n",
       "   similarity_scores  Year Month Day   fyear  \n",
       "0                100  2020   Jun   1  2019.0  \n",
       "1                100  2020   May  20  2019.0  \n",
       "2                100  2020   May   8  2019.0  \n",
       "3                100  2020   May  30  2019.0  \n",
       "4                100  2020   May  11  2019.0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Jun', 'May', 'Apr', 'Feb', 'Jan', 'Dec', 'Nov', 'Oct', 'Aug',\n",
       "       'Sep', 'Jul', 'Mar'], dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Month'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dict = {\n",
    "    'Jun' : '06', 'May' : '05', 'Apr' : '04', 'Feb' : '02', 'Jan' : '01' , 'Dec' : '12', 'Nov' : '11', 'Oct' : '10' , 'Aug' : '08',\n",
    "       'Sep' : '09', 'Jul' : '07', 'Mar' : '03'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_no_list = []\n",
    "for i in range(0,len(df_new)):\n",
    "    month_no_list.append(month_dict[df_new['Month'][i]])\n",
    "df_new['Month_'] = month_no_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_no_list = []\n",
    "for i in range(0,len(df_new)):\n",
    "    if(int(df_new['Day'][i]) >= 1 and int(df_new['Day'][i]) <= 9):\n",
    "        day_no_list.append('0'+ df_new['Day'][i])\n",
    "    else:\n",
    "        day_no_list.append(df_new['Day'][i])\n",
    "    \n",
    "df_new['Day_'] = day_no_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put correct dateyear in each row\n",
    "dateyear_list = []\n",
    "for i in range(0,len(df_new)):\n",
    "    conf_time = df_new['Year'][i] + '-' + f\"{df_new['Month_'][i]}\" + '-' + f\"{df_new['Day_'][i]}\"\n",
    "    \n",
    "    if(conf_time < myDict[df_new['CIK'][i]][int(df_new['Year'][i])-1989].date().strftime('%Y-%m-%d')):\n",
    "         # prev dateyear\n",
    "        dateyear = myDict[df_new['CIK'][i]][int(df_new['Year'][i])-1989-1].date().strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        # same dateyear\n",
    "        dateyear = myDict[df_new['CIK'][i]][int(df_new['Year'][i])-1989].date().strftime('%Y-%m-%d')\n",
    "    dateyear_list.append(dateyear)\n",
    "df_new['dateyear'] = dateyear_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "for i in range(0,len(df_new)):\n",
    "    if(df_new['Year'][i] == df_new['dateyear'][i].replace('-', ' ').split(' ')[0]):\n",
    "        count1 += 1\n",
    "    else:\n",
    "        count2 += 1\n",
    "# count1(conference with same conf_year and dateyear) is more than count2 (conference with different conf_year and dateyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_time_list = []\n",
    "for i in range(0,len(df_new)):\n",
    "    conf_time_list.append(df_new['Year'][i] + '-' + f\"{df_new['Month_'][i]}\" + '-' + f\"{df_new['Day_'][i]}\")\n",
    "df_new['conf_time'] = conf_time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new2 = df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Field1</th>\n",
       "      <th>Field2_Text</th>\n",
       "      <th>Field3</th>\n",
       "      <th>tickers</th>\n",
       "      <th>company_names_seekingalpha</th>\n",
       "      <th>CIK</th>\n",
       "      <th>company_names_database</th>\n",
       "      <th>similarity_scores</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>fyear</th>\n",
       "      <th>Month_</th>\n",
       "      <th>Day_</th>\n",
       "      <th>dateyear</th>\n",
       "      <th>conf_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...</td>\n",
       "      <td>Jun.  1, 2020  2:30 PM ET</td>\n",
       "      <td>EOG Resources, Inc. (EOG)</td>\n",
       "      <td>EOG Resources, Inc. (NYSE:EOG) AllianceBernste...</td>\n",
       "      <td>EOG</td>\n",
       "      <td>EOG Resources, Inc.</td>\n",
       "      <td>0000821189</td>\n",
       "      <td>EOG RESOURCES INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jun</td>\n",
       "      <td>1</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>06</td>\n",
       "      <td>01</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2020-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...</td>\n",
       "      <td>May 20, 2020  5:35 PM ET</td>\n",
       "      <td>Eaton Vance Corp. (EV)</td>\n",
       "      <td>Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...</td>\n",
       "      <td>EV</td>\n",
       "      <td>Eaton Vance Corp.</td>\n",
       "      <td>0000350797</td>\n",
       "      <td>EATON VANCE CORP</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>20</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>05</td>\n",
       "      <td>20</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>2020-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...</td>\n",
       "      <td>May  8, 2020  5:25 PM ET</td>\n",
       "      <td>Whitestone REIT (WSR)</td>\n",
       "      <td>Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...</td>\n",
       "      <td>WSR</td>\n",
       "      <td>Whitestone REIT</td>\n",
       "      <td>0001175535</td>\n",
       "      <td>WHITESTONE REIT</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>8</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>05</td>\n",
       "      <td>08</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2020-05-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...   \n",
       "1  Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...   \n",
       "2  Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...   \n",
       "\n",
       "                      Field1                Field2_Text  \\\n",
       "0  Jun.  1, 2020  2:30 PM ET  EOG Resources, Inc. (EOG)   \n",
       "1   May 20, 2020  5:35 PM ET     Eaton Vance Corp. (EV)   \n",
       "2   May  8, 2020  5:25 PM ET      Whitestone REIT (WSR)   \n",
       "\n",
       "                                              Field3 tickers  \\\n",
       "0  EOG Resources, Inc. (NYSE:EOG) AllianceBernste...     EOG   \n",
       "1  Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...      EV   \n",
       "2  Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...     WSR   \n",
       "\n",
       "  company_names_seekingalpha         CIK company_names_database  \\\n",
       "0        EOG Resources, Inc.  0000821189      EOG RESOURCES INC   \n",
       "1          Eaton Vance Corp.  0000350797       EATON VANCE CORP   \n",
       "2            Whitestone REIT  0001175535        WHITESTONE REIT   \n",
       "\n",
       "   similarity_scores  Year Month Day   fyear Month_ Day_    dateyear  \\\n",
       "0                100  2020   Jun   1  2019.0     06   01  2019-12-31   \n",
       "1                100  2020   May  20  2019.0     05   20  2019-10-31   \n",
       "2                100  2020   May   8  2019.0     05   08  2019-12-31   \n",
       "\n",
       "    conf_time  \n",
       "0  2020-06-01  \n",
       "1  2020-05-20  \n",
       "2  2020-05-08  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add quarter column\n",
    "def date_range(start, end, intv):\n",
    "    from datetime import datetime\n",
    "    start = datetime.strptime(start,\"%Y%m%d\")\n",
    "    end = datetime.strptime(end,\"%Y%m%d\")\n",
    "    diff = (end  - start ) / intv\n",
    "    for i in range(intv):\n",
    "        yield (start + diff * i).strftime(\"%Y%m%d\")\n",
    "    yield end.strftime(\"%Y%m%d\")\n",
    "\n",
    "quarters_list = []\n",
    "\n",
    "for i in range(0,len(df_new)):\n",
    "    conf_date = df_new['conf_time'][i].replace('-','')\n",
    "    \n",
    "    dateyear_i = df_new['dateyear'][i].replace('-','')\n",
    "    \n",
    "    dateyear_year = df_new['dateyear'][i].split('-')[0]\n",
    "    dateyear_f = myDict[df_new['CIK'][i]][int(dateyear_year)-1989+1].date().strftime('%Y%m%d')\n",
    "    \n",
    "    intervals = list(date_range(dateyear_i,dateyear_f, 4))\n",
    "    \n",
    "    \n",
    "    if(conf_date >= intervals[0] and conf_date < intervals[1]):\n",
    "        quarters_list.append(1)\n",
    "    elif(conf_date >= intervals[1] and conf_date < intervals[2]):\n",
    "        quarters_list.append(2)\n",
    "    elif(conf_date >= intervals[2] and conf_date < intervals[3]):\n",
    "        quarters_list.append(3)\n",
    "    elif(conf_date >= intervals[3] and conf_date < intervals[4]):\n",
    "        quarters_list.append(4)\n",
    "\n",
    "df_new['quarter'] = quarters_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Field1</th>\n",
       "      <th>Field2_Text</th>\n",
       "      <th>Field3</th>\n",
       "      <th>tickers</th>\n",
       "      <th>company_names_seekingalpha</th>\n",
       "      <th>CIK</th>\n",
       "      <th>company_names_database</th>\n",
       "      <th>similarity_scores</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>fyear</th>\n",
       "      <th>Month_</th>\n",
       "      <th>Day_</th>\n",
       "      <th>dateyear</th>\n",
       "      <th>conf_time</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...</td>\n",
       "      <td>Jun.  1, 2020  2:30 PM ET</td>\n",
       "      <td>EOG Resources, Inc. (EOG)</td>\n",
       "      <td>EOG Resources, Inc. (NYSE:EOG) AllianceBernste...</td>\n",
       "      <td>EOG</td>\n",
       "      <td>EOG Resources, Inc.</td>\n",
       "      <td>0000821189</td>\n",
       "      <td>EOG RESOURCES INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jun</td>\n",
       "      <td>1</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>06</td>\n",
       "      <td>01</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...   \n",
       "\n",
       "                      Field1                Field2_Text  \\\n",
       "0  Jun.  1, 2020  2:30 PM ET  EOG Resources, Inc. (EOG)   \n",
       "\n",
       "                                              Field3 tickers  \\\n",
       "0  EOG Resources, Inc. (NYSE:EOG) AllianceBernste...     EOG   \n",
       "\n",
       "  company_names_seekingalpha         CIK company_names_database  \\\n",
       "0        EOG Resources, Inc.  0000821189      EOG RESOURCES INC   \n",
       "\n",
       "   similarity_scores  Year Month Day   fyear Month_ Day_    dateyear  \\\n",
       "0                100  2020   Jun   1  2019.0     06   01  2019-12-31   \n",
       "\n",
       "    conf_time  quarter  \n",
       "0  2020-06-01        2  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_sorted1 = df_new.sort_values(by=[\"CIK\",'conf_time'], kind=\"mergesort\").reset_index(drop = True)\n",
    "df_new_sorted2 = df_new.sort_values(by=[\"CIK\",'dateyear','quarter'], kind=\"mergesort\").reset_index(drop = True)\n",
    "df_new_sorted3 = df_new.sort_values(by=[\"CIK\",'dateyear'], kind=\"mergesort\").reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from nltk.corpus import stopwords\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# import re\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sentence-transformers in c:\\users\\user\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: sentencepiece in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.1.96)\n",
      "Requirement already satisfied, skipping upgrade: nltk in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers) (3.5)\n",
      "Requirement already satisfied, skipping upgrade: huggingface-hub in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.0.12)\n",
      "Requirement already satisfied, skipping upgrade: torchvision in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.23.2)\n",
      "Requirement already satisfied, skipping upgrade: transformers<5.0.0,>=4.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.8.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: torch>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.9.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.50.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.19.2)\n",
      "Requirement already satisfied, skipping upgrade: regex in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (2020.10.15)\n",
      "Requirement already satisfied, skipping upgrade: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (0.17.0)\n",
      "Requirement already satisfied, skipping upgrade: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=20.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub->sentence-transformers) (21.0)\n",
      "Requirement already satisfied, skipping upgrade: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied, skipping upgrade: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub->sentence-transformers) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub->sentence-transformers) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=5.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers) (8.0.1)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: tokenizers<0.11,>=0.10.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.10.3)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: sacremoses in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.45)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging>=20.9->huggingface-hub->sentence-transformers) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->sentence-transformers) (1.25.11)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->sentence-transformers) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->sentence-transformers) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# tf_idf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "stop_words_l = stopwords.words('english')\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "!pip install -U sentence-transformers\n",
    "\n",
    "\n",
    "# word2Vec\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import gensim\n",
    "\n",
    "global W2V_PATH\n",
    "global model_w2v\n",
    "W2V_PATH = \"GoogleNews-vectors-negative300.bin.gz\"\n",
    "model_w2v = gensim.models.KeyedVectors.load_word2vec_format(W2V_PATH, binary=True)\n",
    "\n",
    "\n",
    "# doc2Vec\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# GloVe\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "embeddings_index = dict()\n",
    "\n",
    "with open('glove.6B.100d.txt', encoding = \"UTF-8\") as file:\n",
    "    for line in file:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "\n",
    "# bert\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "global sbert_model\n",
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scores:\n",
    "\n",
    "    def return_score(\n",
    "        self,\n",
    "        pairwise_similarities,\n",
    "        pairwise_differences,\n",
    "        matrix,\n",
    "        ):\n",
    "        if matrix == 'Cosine Similarity':\n",
    "            score1 = pairwise_similarities[0][1]\n",
    "        elif matrix == 'Euclidean Distance':\n",
    "            score1 = pairwise_differences[0][1]\n",
    "        return score1\n",
    "\n",
    "    # def stopword(self, documents_df):\n",
    "\n",
    "    #     stop_words_l = stopwords.words('english')\n",
    "    #     documents_df['Field3'] = \\\n",
    "    #         documents_df.documents.apply(lambda x: \\\n",
    "    #             ' '.join(re.sub(r'[^a-zA-Z]', ' ', w).lower() for w in\n",
    "    #             x.split() if re.sub(r'[^a-zA-Z]', ' ', w).lower()\n",
    "    #             not in stop_words_l))\n",
    "    #     return documents_df\n",
    "\n",
    "    def tf_idf_vectorizer(self, documents_df):\n",
    "\n",
    "        tfidfvectoriser = TfidfVectorizer()\n",
    "        tfidfvectoriser.fit(documents_df.Field3)\n",
    "        tfidf_vectors = \\\n",
    "            tfidfvectoriser.transform(documents_df.Field3)\n",
    "\n",
    "        return (tfidfvectoriser, tfidf_vectors)\n",
    "\n",
    "    def doc2Vec(self, documents_df, matrix):\n",
    "\n",
    "        tagged_data = [TaggedDocument(words=word_tokenize(doc),\n",
    "                       tags=[i]) for (i, doc) in\n",
    "                       enumerate(documents_df.Field3)]\n",
    "        model_d2v = Doc2Vec(vector_size=100, alpha=0.025, min_count=1)\n",
    "\n",
    "        model_d2v.build_vocab(tagged_data)\n",
    "\n",
    "        for epoch in range(100):\n",
    "            model_d2v.train(tagged_data,\n",
    "                            total_examples=model_d2v.corpus_count,\n",
    "                            epochs=model_d2v.epochs)\n",
    "\n",
    "        document_embeddings = np.zeros((documents_df.shape[0], 100))\n",
    "\n",
    "        for i in range(len(document_embeddings)):\n",
    "            document_embeddings[i] = model_d2v.docvecs[i]\n",
    "\n",
    "        pairwise_similarities = cosine_similarity(document_embeddings)\n",
    "        pairwise_differences = euclidean_distances(document_embeddings)\n",
    "\n",
    "        return self.return_score(pairwise_similarities,\n",
    "                                 pairwise_differences, matrix)\n",
    "\n",
    "    def word2Vec(self, documents_df, matrix):\n",
    "\n",
    "        tokenizer = Tokenizer()\n",
    "        tokenizer.fit_on_texts(documents_df.Field3)\n",
    "        tokenized_documents = \\\n",
    "            tokenizer.texts_to_sequences(documents_df.Field3)\n",
    "        tokenized_paded_documents = pad_sequences(tokenized_documents,\n",
    "                maxlen=64, padding='post')\n",
    "        vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "        embedding_matrix = np.zeros((vocab_size, 300))\n",
    "        for (word, i) in tokenizer.word_index.items():\n",
    "            if word in model_w2v:\n",
    "                embedding_matrix[i] = model_w2v[word]\n",
    "\n",
    "        document_word_embeddings = \\\n",
    "            np.zeros((len(tokenized_paded_documents), 64, 300))\n",
    "        for i in range(len(tokenized_paded_documents)):\n",
    "            for j in range(len(tokenized_paded_documents[0])):\n",
    "                document_word_embeddings[i][j] = \\\n",
    "                    embedding_matrix[tokenized_paded_documents[i][j]]\n",
    "\n",
    "        document_embeddings = np.zeros((len(tokenized_paded_documents),\n",
    "                300))\n",
    "\n",
    "        (tfidfvectoriser, tfidf_vectors) = \\\n",
    "            self.tf_idf_vectorizer(documents_df)\n",
    "\n",
    "        words = tfidfvectoriser.get_feature_names()\n",
    "\n",
    "        for i in range(len(document_word_embeddings)):\n",
    "            for j in range(len(words)):\n",
    "                a = tfidf_vectors[i].toarray().T\n",
    "                document_embeddings[i] += \\\n",
    "                    embedding_matrix[tokenizer.word_index[words[j]]] \\\n",
    "                    * a[j]\n",
    "\n",
    "        pairwise_similarities = cosine_similarity(document_embeddings)\n",
    "        pairwise_differences = euclidean_distances(document_embeddings)\n",
    "\n",
    "        return self.return_score(pairwise_similarities,\n",
    "                                 pairwise_differences, matrix)\n",
    "\n",
    "    def tf_idf(self, documents_df, matrix):\n",
    "\n",
    "        (tfidfvectoriser, tfidf_vectors) = \\\n",
    "            self.tf_idf_vectorizer(documents_df)\n",
    "\n",
    "        pairwise_similarities = np.dot(tfidf_vectors,\n",
    "                tfidf_vectors.T).toarray()\n",
    "        pairwise_differences = euclidean_distances(tfidf_vectors)\n",
    "\n",
    "        return self.return_score(pairwise_similarities,\n",
    "                                 pairwise_differences, matrix)\n",
    "\n",
    "    def gloVe(self, documents_df, matrix):\n",
    "\n",
    "        tokenizer = Tokenizer()\n",
    "        tokenizer.fit_on_texts(documents_df.Field3)\n",
    "        tokenized_documents = \\\n",
    "            tokenizer.texts_to_sequences(documents_df.Field3)\n",
    "        tokenized_paded_documents = pad_sequences(tokenized_documents,\n",
    "                maxlen=64, padding='post')\n",
    "        vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "        # embeddings_index = dict()\n",
    "\n",
    "        # with open('glove.6B.100d.txt') as file:\n",
    "        #     for line in file:\n",
    "        #         values = line.split()\n",
    "        #         word = values[0]\n",
    "        #         coefs = np.asarray(values[1:], dtype='float32')\n",
    "        #         embeddings_index[word] = coefs\n",
    "\n",
    "        embedding_matrix = np.zeros((vocab_size, 100))\n",
    "        #print(embedding_matrix)\n",
    "        for (word, i) in tokenizer.word_index.items():\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "\n",
    "        document_embeddings = np.zeros((len(tokenized_paded_documents),\n",
    "                100))\n",
    "\n",
    "        (tfidfvectoriser, tfidf_vectors) = \\\n",
    "            self.tf_idf_vectorizer(documents_df)\n",
    "\n",
    "        words = tfidfvectoriser.get_feature_names()\n",
    "\n",
    "        for i in range(documents_df.shape[0]):\n",
    "            for j in range(len(words)):\n",
    "                #print(i,j)\n",
    "                a = tfidf_vectors[i].toarray().T\n",
    "                document_embeddings[i] += embedding_matrix[tokenizer.word_index[words[j]]] * a[j]\n",
    "                \n",
    "\n",
    "        pairwise_similarities = cosine_similarity(document_embeddings)\n",
    "        pairwise_differences = euclidean_distances(document_embeddings)\n",
    "\n",
    "        return self.return_score(pairwise_similarities,\n",
    "                                 pairwise_differences, matrix)\n",
    "\n",
    "    def bert(self, documents_df, matrix):\n",
    "\n",
    "        document_embeddings = \\\n",
    "            sbert_model.encode(documents_df['Field3'])\n",
    "\n",
    "        pairwise_similarities = cosine_similarity(document_embeddings)\n",
    "        pairwise_differences = euclidean_distances(document_embeddings)\n",
    "\n",
    "        return self.return_score(pairwise_similarities,\n",
    "                                 pairwise_differences, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiprocessing\n",
    "def split_dataframe(df, chunk_size = 10000): \n",
    "    chunks = list()\n",
    "    num_chunks = len(df) // chunk_size + 1\n",
    "    for i in range(num_chunks):\n",
    "        chunks.append(df[i*chunk_size:(i+1)*chunk_size])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores.gloVe(documents_df,'Cosine Similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # score funcition for calculating score between any two documents\n",
    "# def score(documents_df,matrix):\n",
    "    \n",
    "#     stop_words_l=stopwords.words('english')\n",
    "#     documents_df['documents_cleaned']=documents_df.Field3.apply(lambda x: \" \".join(re.sub(r'[^a-zA-Z]',' ',w).lower() for w in x.split() if re.sub(r'[^a-zA-Z]',' ',w).lower() not in stop_words_l) )\n",
    "    \n",
    "    \n",
    "#     tfidfvectoriser=TfidfVectorizer()\n",
    "#     tfidfvectoriser.fit(documents_df.documents_cleaned)\n",
    "#     tfidf_vectors=tfidfvectoriser.transform(documents_df.documents_cleaned)\n",
    "\n",
    "#     pairwise_similarities=np.dot(tfidf_vectors,tfidf_vectors.T).toarray()\n",
    "#     pairwise_differences=euclidean_distances(tfidf_vectors)\n",
    "    \n",
    "    \n",
    "#     if matrix=='Cosine Similarity':\n",
    "#         score1 = pairwise_similarities[0][1]\n",
    "#     elif matrix=='Euclidean Distance':\n",
    "#         score1 = pairwise_differences[0][1]\n",
    "#     return score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = Scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# per Conference df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_conference = df_new_sorted1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Field1</th>\n",
       "      <th>Field2_Text</th>\n",
       "      <th>Field3</th>\n",
       "      <th>tickers</th>\n",
       "      <th>company_names_seekingalpha</th>\n",
       "      <th>CIK</th>\n",
       "      <th>company_names_database</th>\n",
       "      <th>similarity_scores</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>fyear</th>\n",
       "      <th>Month_</th>\n",
       "      <th>Day_</th>\n",
       "      <th>dateyear</th>\n",
       "      <th>conf_time</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAR Corp. F3Q08 (Qtr End 02/29/08) Earnings Ca...</td>\n",
       "      <td>Mar. 19, 2008  2:05 PM ET</td>\n",
       "      <td>AAR Corp. (AIR)</td>\n",
       "      <td>AAR Corp. (NYSE:AIR) F3Q08 (Qtr End 02/29/08) ...</td>\n",
       "      <td>AIR</td>\n",
       "      <td>AAR Corp.</td>\n",
       "      <td>0000001750</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>100</td>\n",
       "      <td>2008</td>\n",
       "      <td>Mar</td>\n",
       "      <td>19</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>03</td>\n",
       "      <td>19</td>\n",
       "      <td>2007-05-30</td>\n",
       "      <td>2008-03-19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAR Corp. F3Q08 (Qtr End 02/29/08) Earnings Ca...</td>\n",
       "      <td>Mar. 19, 2008  2:05 PM ET</td>\n",
       "      <td>AAR Corp. (AIR)</td>\n",
       "      <td>AAR Corp. (NYSE:AIR) F3Q08 (Qtr End 02/29/08) ...</td>\n",
       "      <td>AIR</td>\n",
       "      <td>AAR Corp.</td>\n",
       "      <td>0000001750</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>100</td>\n",
       "      <td>2008</td>\n",
       "      <td>Mar</td>\n",
       "      <td>19</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>03</td>\n",
       "      <td>19</td>\n",
       "      <td>2007-05-30</td>\n",
       "      <td>2008-03-19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  AAR Corp. F3Q08 (Qtr End 02/29/08) Earnings Ca...   \n",
       "1  AAR Corp. F3Q08 (Qtr End 02/29/08) Earnings Ca...   \n",
       "\n",
       "                      Field1      Field2_Text  \\\n",
       "0  Mar. 19, 2008  2:05 PM ET  AAR Corp. (AIR)   \n",
       "1  Mar. 19, 2008  2:05 PM ET  AAR Corp. (AIR)   \n",
       "\n",
       "                                              Field3 tickers  \\\n",
       "0  AAR Corp. (NYSE:AIR) F3Q08 (Qtr End 02/29/08) ...     AIR   \n",
       "1  AAR Corp. (NYSE:AIR) F3Q08 (Qtr End 02/29/08) ...     AIR   \n",
       "\n",
       "  company_names_seekingalpha         CIK company_names_database  \\\n",
       "0                  AAR Corp.  0000001750               AAR CORP   \n",
       "1                  AAR Corp.  0000001750               AAR CORP   \n",
       "\n",
       "   similarity_scores  Year Month Day   fyear Month_ Day_    dateyear  \\\n",
       "0                100  2008   Mar  19  2007.0     03   19  2007-05-30   \n",
       "1                100  2008   Mar  19  2007.0     03   19  2007-05-30   \n",
       "\n",
       "    conf_time  quarter  \n",
       "0  2008-03-19        4  \n",
       "1  2008-03-19        4  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_per_conference.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_conference1 = df_per_conference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_per_conference1[['CIK','conf_time','Field3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202632"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2021-07-16 11:11:38\n",
      "1001 2021-07-16 11:28:08\n",
      "2001 2021-07-16 11:44:57\n",
      "3001 2021-07-16 12:01:36\n",
      "4001 2021-07-16 12:18:20\n",
      "5001 2021-07-16 12:34:54\n",
      "6001 2021-07-16 12:51:29\n",
      "7001 2021-07-16 13:08:45\n",
      "8001 2021-07-16 13:25:26\n",
      "9001 2021-07-16 13:41:57\n",
      "10001 2021-07-16 13:58:40\n",
      "11001 2021-07-16 14:15:47\n",
      "12001 2021-07-16 14:32:53\n",
      "13001 2021-07-16 14:50:01\n",
      "14001 2021-07-16 15:06:57\n",
      "15001 2021-07-16 15:23:53\n",
      "16001 2021-07-16 15:40:50\n",
      "17001 2021-07-16 15:57:58\n",
      "18001 2021-07-16 16:14:54\n",
      "19001 2021-07-16 16:32:12\n",
      "20001 2021-07-16 16:48:59\n",
      "21001 2021-07-16 17:06:02\n",
      "22001 2021-07-16 17:23:03\n",
      "23001 2021-07-16 17:39:59\n",
      "24001 2021-07-16 17:57:07\n",
      "25001 2021-07-16 18:14:04\n",
      "26001 2021-07-16 18:31:18\n",
      "27001 2021-07-16 18:48:42\n",
      "28001 2021-07-16 19:05:56\n",
      "29001 2021-07-16 19:23:02\n",
      "30001 2021-07-16 19:39:53\n",
      "31001 2021-07-16 19:56:55\n",
      "32001 2021-07-16 20:13:58\n",
      "33001 2021-07-16 20:31:13\n",
      "34001 2021-07-16 20:48:08\n",
      "35001 2021-07-16 21:05:36\n",
      "36001 2021-07-16 21:22:38\n",
      "37001 2021-07-16 21:39:41\n",
      "38001 2021-07-16 21:56:38\n",
      "39001 2021-07-16 22:13:30\n",
      "40001 2021-07-16 22:30:28\n",
      "41001 2021-07-16 22:47:20\n",
      "42001 2021-07-16 23:04:06\n",
      "43001 2021-07-16 23:21:06\n",
      "44001 2021-07-16 23:38:03\n",
      "45001 2021-07-16 23:55:12\n",
      "46001 2021-07-17 00:12:03\n",
      "47001 2021-07-17 00:28:55\n",
      "48001 2021-07-17 00:45:52\n",
      "49001 2021-07-17 01:02:52\n",
      "50001 2021-07-17 01:19:49\n",
      "51001 2021-07-17 01:36:40\n",
      "52001 2021-07-17 01:53:55\n",
      "53001 2021-07-17 02:10:51\n",
      "54001 2021-07-17 02:27:50\n",
      "55001 2021-07-17 02:44:58\n",
      "56001 2021-07-17 03:01:52\n",
      "57001 2021-07-17 03:19:02\n",
      "58001 2021-07-17 03:36:01\n",
      "59001 2021-07-17 03:52:57\n",
      "60001 2021-07-17 04:10:08\n"
     ]
    }
   ],
   "source": [
    "# score calculating logic per dateyear\n",
    "\n",
    "#x['Cosine_Similarity'] = \"\"\n",
    "#x['Euclidean_Distance'] = \"\"\n",
    "import datetime\n",
    "x['bert_c'] = \"\"\n",
    "x['word2Vec_c'] = \"\"\n",
    "x['doc2Vec_c'] = \"\"\n",
    "x['golVe_c'] = \"\"\n",
    "x['tf_idf_c'] = \"\"\n",
    "x['bert_e'] = \"\"\n",
    "x['word2Vec_e'] = \"\"\n",
    "x['doc2Vec_e'] = \"\"\n",
    "x['golVe_e'] = \"\"\n",
    "x['tf_idf_e'] = \"\"\n",
    "\n",
    "index_list = x.index.tolist()\n",
    "\n",
    "for i in range(1,len(x)):\n",
    "\n",
    "    if i%1000==1:\n",
    "        tm = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(i,tm)\n",
    "    documents_df = x.iloc[i-1:i+1,2].reset_index(drop = True).to_frame()\n",
    "\n",
    "    \n",
    "#     cosine = score(documents_df,'Cosine Similarity')\n",
    "#     euclidean = score(documents_df,'Euclidean Distance')\n",
    "\n",
    "    #x['Cosine_Similarity'][index_list[i]] = cosine\n",
    "    #x['Euclidean_Distance'][index_list[i]] = euclidean\n",
    "    \n",
    "    \n",
    "    #stop_words_l = stopwords.words('english')\n",
    "#     documents_df['Field3'] = \\\n",
    "#         documents_df.Field3.apply(lambda x: \\\n",
    "#             ' '.join(re.sub(r'[^a-zA-Z]', ' ', w).lower() for w in\n",
    "#             x.split() if re.sub(r'[^a-zA-Z]', ' ', w).lower()\n",
    "#             not in stop_words_l))\n",
    "\n",
    "\n",
    "    bert_c = scores.bert(documents_df,'Cosine Similarity')\n",
    "    #word2Vec_c = scores.word2Vec(documents_df,'Cosine Similarity')\n",
    "    #doc2Vec_c = scores.doc2Vec(documents_df,'Cosine Similarity')\n",
    "    #golVe_c = scores.gloVe(documents_df,'Cosine Similarity')\n",
    "    tf_idf_c = scores.tf_idf(documents_df,'Cosine Similarity')\n",
    "    bert_e = scores.bert(documents_df,'Euclidean Distance')\n",
    "    #word2Vec_e = scores.word2Vec(documents_df,'Euclidean Distance')\n",
    "    #doc2Vec_e = scores.doc2Vec(documents_df,'Euclidean Distance')\n",
    "    #golVe_e = scores.gloVe(documents_df,'Euclidean Distance')\n",
    "    tf_idf_e = scores.tf_idf(documents_df,'Euclidean Distance')\n",
    "\n",
    "\n",
    "    x['bert_c'][index_list[i]] = bert_c\n",
    "    #x['word2Vec_c'][index_list[i]] = word2Vec_c\n",
    "    #x['doc2Vec_c'][index_list[i]] = doc2Vec_c\n",
    "    #x['golVe_c'][index_list[i]] = gloVe_c\n",
    "    x['tf_idf_c'][index_list[i]] = tf_idf_c\n",
    "    x['bert_e'][index_list[i]] = bert_e\n",
    "    #x['word2Vec_e'][index_list[i]] = word2Vec_e\n",
    "    #x['doc2Vec_e'][index_list[i]] = doc2Vec_e\n",
    "    #x['golVe_e'][index_list[i]] = gloVe_e\n",
    "    x['tf_idf_e'][index_list[i]] = tf_idf_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>conf_time</th>\n",
       "      <th>Field3</th>\n",
       "      <th>bert_c</th>\n",
       "      <th>word2Vec_c</th>\n",
       "      <th>doc2Vec_c</th>\n",
       "      <th>golVe_c</th>\n",
       "      <th>tf_idf_c</th>\n",
       "      <th>bert_e</th>\n",
       "      <th>word2Vec_e</th>\n",
       "      <th>doc2Vec_e</th>\n",
       "      <th>golVe_e</th>\n",
       "      <th>tf_idf_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2017-12-21</td>\n",
       "      <td>AAR Corp (NYSE:AIR) Q2 2018 Earnings Conferenc...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2018-03-20</td>\n",
       "      <td>AAR Corporation (NYSE:AIR) Q3 2018 Earnings Co...</td>\n",
       "      <td>0.969271</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.943457</td>\n",
       "      <td>3.785</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.336282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2018-07-11</td>\n",
       "      <td>AAR Corporation (NYSE:AIR) Q4 2018 Earnings Co...</td>\n",
       "      <td>0.888331</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.929147</td>\n",
       "      <td>7.19139</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.37644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2018-07-11</td>\n",
       "      <td>AAR Corporation (NYSE:AIR) Q4 2018 Earnings Co...</td>\n",
       "      <td>0.981526</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.996847</td>\n",
       "      <td>2.9262</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0794113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2018-09-25</td>\n",
       "      <td>AAR Corporation (NYSE:AIR) Q1 2019 Earnings Co...</td>\n",
       "      <td>0.88278</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.900856</td>\n",
       "      <td>7.33254</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.445295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0000001800</td>\n",
       "      <td>2013-10-16</td>\n",
       "      <td>The following audio is from a conference call ...</td>\n",
       "      <td>0.598123</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.235979</td>\n",
       "      <td>13.5358</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.23614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0000001800</td>\n",
       "      <td>2013-10-16</td>\n",
       "      <td>Abbott Laboratories (NYSE:ABT) Q3 2013 Earning...</td>\n",
       "      <td>0.58984</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.354778</td>\n",
       "      <td>13.6942</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.13598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0000001800</td>\n",
       "      <td>2014-01-22</td>\n",
       "      <td>Abbott Laboratories (NYSE:ABT) Q4 2013 Earning...</td>\n",
       "      <td>0.929657</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.9729</td>\n",
       "      <td>5.72085</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.232809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0000001800</td>\n",
       "      <td>2014-04-16</td>\n",
       "      <td>The following audio is from a conference call ...</td>\n",
       "      <td>0.625952</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.344333</td>\n",
       "      <td>13.0985</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.14514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0000001800</td>\n",
       "      <td>2014-04-16</td>\n",
       "      <td>Abbott Laboratories (NYSE:ABT) Q1 2014 Results...</td>\n",
       "      <td>0.684819</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.361358</td>\n",
       "      <td>12.0513</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.13017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           CIK   conf_time                                             Field3  \\\n",
       "30  0000001750  2017-12-21  AAR Corp (NYSE:AIR) Q2 2018 Earnings Conferenc...   \n",
       "31  0000001750  2018-03-20  AAR Corporation (NYSE:AIR) Q3 2018 Earnings Co...   \n",
       "32  0000001750  2018-07-11  AAR Corporation (NYSE:AIR) Q4 2018 Earnings Co...   \n",
       "33  0000001750  2018-07-11  AAR Corporation (NYSE:AIR) Q4 2018 Earnings Co...   \n",
       "34  0000001750  2018-09-25  AAR Corporation (NYSE:AIR) Q1 2019 Earnings Co...   \n",
       "..         ...         ...                                                ...   \n",
       "95  0000001800  2013-10-16  The following audio is from a conference call ...   \n",
       "96  0000001800  2013-10-16  Abbott Laboratories (NYSE:ABT) Q3 2013 Earning...   \n",
       "97  0000001800  2014-01-22  Abbott Laboratories (NYSE:ABT) Q4 2013 Earning...   \n",
       "98  0000001800  2014-04-16  The following audio is from a conference call ...   \n",
       "99  0000001800  2014-04-16  Abbott Laboratories (NYSE:ABT) Q1 2014 Results...   \n",
       "\n",
       "      bert_c word2Vec_c doc2Vec_c golVe_c  tf_idf_c   bert_e word2Vec_e  \\\n",
       "30                                                                        \n",
       "31  0.969271                               0.943457    3.785              \n",
       "32  0.888331                               0.929147  7.19139              \n",
       "33  0.981526                               0.996847   2.9262              \n",
       "34   0.88278                               0.900856  7.33254              \n",
       "..       ...        ...       ...     ...       ...      ...        ...   \n",
       "95  0.598123                               0.235979  13.5358              \n",
       "96   0.58984                               0.354778  13.6942              \n",
       "97  0.929657                                 0.9729  5.72085              \n",
       "98  0.625952                               0.344333  13.0985              \n",
       "99  0.684819                               0.361358  12.0513              \n",
       "\n",
       "   doc2Vec_e golVe_e   tf_idf_e  \n",
       "30                               \n",
       "31                     0.336282  \n",
       "32                      0.37644  \n",
       "33                    0.0794113  \n",
       "34                     0.445295  \n",
       "..       ...     ...        ...  \n",
       "95                      1.23614  \n",
       "96                      1.13598  \n",
       "97                     0.232809  \n",
       "98                      1.14514  \n",
       "99                      1.13017  \n",
       "\n",
       "[70 rows x 13 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# per quarter df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_quarter = df_new_sorted2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_quarter2 = df_per_quarter[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_agg2 = lambda x: ' '.join(x)\n",
    "df_2 = df_per_quarter2.groupby(['CIK','dateyear','quarter']).agg({'Field3':array_agg2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Field3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CIK</th>\n",
       "      <th>dateyear</th>\n",
       "      <th>quarter</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">0000001750</th>\n",
       "      <th>2007-05-30</th>\n",
       "      <th>4</th>\n",
       "      <td>AAR Corp. (NYSE:AIR) F3Q08 (Qtr End 02/29/08) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-05-30</th>\n",
       "      <th>4</th>\n",
       "      <td>AAR CORP. (NYSE:AIR) F3Q09 (Qtr End 02/28/09) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-30</th>\n",
       "      <th>4</th>\n",
       "      <td>AAR (NYSE:AIR) Q3 2013 Earnings Call March 19,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2013-05-30</th>\n",
       "      <th>1</th>\n",
       "      <td>AAR Corp. (NYSE:AIR) Q4 2013 Earnings Call Jul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAR (NYSE:AIR) Q1 2014 Earnings Call September...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAR (NYSE:AIR) Q2 2014 Earnings Call December ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAR Corp (NYSE:AIR) F3Q2014 Earnings Conferenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-30</th>\n",
       "      <th>1</th>\n",
       "      <td>AAR Corporation (NYSE:AIR) Q4 2014 Earnings Co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          Field3\n",
       "CIK        dateyear   quarter                                                   \n",
       "0000001750 2007-05-30 4        AAR Corp. (NYSE:AIR) F3Q08 (Qtr End 02/29/08) ...\n",
       "           2008-05-30 4        AAR CORP. (NYSE:AIR) F3Q09 (Qtr End 02/28/09) ...\n",
       "           2012-05-30 4        AAR (NYSE:AIR) Q3 2013 Earnings Call March 19,...\n",
       "           2013-05-30 1        AAR Corp. (NYSE:AIR) Q4 2013 Earnings Call Jul...\n",
       "                      2        AAR (NYSE:AIR) Q1 2014 Earnings Call September...\n",
       "                      3        AAR (NYSE:AIR) Q2 2014 Earnings Call December ...\n",
       "                      4        AAR Corp (NYSE:AIR) F3Q2014 Earnings Conferenc...\n",
       "           2014-05-30 1        AAR Corporation (NYSE:AIR) Q4 2014 Earnings Co..."
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_2.reset_index(inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>dateyear</th>\n",
       "      <th>quarter</th>\n",
       "      <th>Field3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2007-05-30</td>\n",
       "      <td>4</td>\n",
       "      <td>AAR Corp. (NYSE:AIR) F3Q08 (Qtr End 02/29/08) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2008-05-30</td>\n",
       "      <td>4</td>\n",
       "      <td>AAR CORP. (NYSE:AIR) F3Q09 (Qtr End 02/28/09) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2012-05-30</td>\n",
       "      <td>4</td>\n",
       "      <td>AAR (NYSE:AIR) Q3 2013 Earnings Call March 19,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2013-05-30</td>\n",
       "      <td>1</td>\n",
       "      <td>AAR Corp. (NYSE:AIR) Q4 2013 Earnings Call Jul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2013-05-30</td>\n",
       "      <td>2</td>\n",
       "      <td>AAR (NYSE:AIR) Q1 2014 Earnings Call September...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2013-05-30</td>\n",
       "      <td>3</td>\n",
       "      <td>AAR (NYSE:AIR) Q2 2014 Earnings Call December ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2013-05-30</td>\n",
       "      <td>4</td>\n",
       "      <td>AAR Corp (NYSE:AIR) F3Q2014 Earnings Conferenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2014-05-30</td>\n",
       "      <td>1</td>\n",
       "      <td>AAR Corporation (NYSE:AIR) Q4 2014 Earnings Co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CIK    dateyear  quarter  \\\n",
       "0  0000001750  2007-05-30        4   \n",
       "1  0000001750  2008-05-30        4   \n",
       "2  0000001750  2012-05-30        4   \n",
       "3  0000001750  2013-05-30        1   \n",
       "4  0000001750  2013-05-30        2   \n",
       "5  0000001750  2013-05-30        3   \n",
       "6  0000001750  2013-05-30        4   \n",
       "7  0000001750  2014-05-30        1   \n",
       "\n",
       "                                              Field3  \n",
       "0  AAR Corp. (NYSE:AIR) F3Q08 (Qtr End 02/29/08) ...  \n",
       "1  AAR CORP. (NYSE:AIR) F3Q09 (Qtr End 02/28/09) ...  \n",
       "2  AAR (NYSE:AIR) Q3 2013 Earnings Call March 19,...  \n",
       "3  AAR Corp. (NYSE:AIR) Q4 2013 Earnings Call Jul...  \n",
       "4  AAR (NYSE:AIR) Q1 2014 Earnings Call September...  \n",
       "5  AAR (NYSE:AIR) Q2 2014 Earnings Call December ...  \n",
       "6  AAR Corp (NYSE:AIR) F3Q2014 Earnings Conferenc...  \n",
       "7  AAR Corporation (NYSE:AIR) Q4 2014 Earnings Co...  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = y.loc[y['CIK'] == '0000001750']\n",
    "# a\n",
    "# b = a.loc[a['dateyear'] == '2018-05-30']\n",
    "# b\n",
    "# b.iloc[0:3]\n",
    "# b.index.tolist()\n",
    "# document = y.iloc[0:,3].reset_index(drop = True).to_frame()\n",
    "# score(document,'Cosine Similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['bert_c'] = \"\"\n",
    "y['word2Vec_c'] = \"\"\n",
    "y['doc2Vec_c'] = \"\"\n",
    "y['golVe_c'] = \"\"\n",
    "y['tf_idf_c'] = \"\"\n",
    "y['bert_e'] = \"\"\n",
    "y['word2Vec_e'] = \"\"\n",
    "y['doc2Vec_e'] = \"\"\n",
    "y['golVe_e'] = \"\"\n",
    "y['tf_idf_e'] = \"\"\n",
    "\n",
    "CIK_list_2 = list(set(y['CIK'].to_list()))\n",
    "\n",
    "for i in range(0,len(CIK_list_2)):\n",
    "    df_temp_cik_2 = y.loc[y['CIK'] == CIK_list_2[i]]\n",
    "    \n",
    "    for i in range(0,len(df_temp_cik_2)):\n",
    "        dateyear_list_2 = list(set(df_temp_cik_2['dateyear'].to_list()))\n",
    "    \n",
    "        \n",
    "        for i in range(0,len(dateyear_list_2)):\n",
    "            df_temp_dateyear_2 = df_temp_cik_2.loc[df_temp_cik_2['dateyear'] == dateyear_list_2[i]]\n",
    "            \n",
    "            index_list = df_temp_dateyear_2.index.tolist()\n",
    "            \n",
    "            for i in range(1,len(df_temp_dateyear_2)):\n",
    "                documents_df = df_temp_dateyear_2.iloc[i-1:i+1,3].reset_index(drop = True).to_frame()\n",
    "                \n",
    "                # remove from\n",
    "                #cosine = score(documents_df,'Cosine Similarity')\n",
    "                #euclidean = score(documents_df,'Euclidean Distance')\n",
    "                \n",
    "                #y['Cosine_Similarity'][index_list[i]] = cosine\n",
    "                #y['Euclidean_Distance'][index_list[i]] = euclidean\n",
    "                # remove end\n",
    "                \n",
    "#                 stop_words_l = stopwords.words('english')\n",
    "#                 documents_df['Field3'] = \\\n",
    "#                     documents_df.documents.apply(lambda x: \\\n",
    "#                         ' '.join(re.sub(r'[^a-zA-Z]', ' ', w).lower() for w in\n",
    "#                         x.split() if re.sub(r'[^a-zA-Z]', ' ', w).lower()\n",
    "#                         not in stop_words_l))\n",
    "\n",
    "                bert_c = scores.bert(documents_df,'Cosine Similarity')\n",
    "                #word2Vec_c = scores.word2Vec(documents_df,'Cosine Similarity')\n",
    "                #doc2Vec_c = scores.doc2Vec(documents_df,'Cosine Similarity')\n",
    "                #golVe_c = scores.golVe(documents_df,'Cosine Similarity')\n",
    "                tf_idf_c = scores.tf_idf(documents_df,'Cosine Similarity')\n",
    "                bert_e = scores.bert(documents_df,'Euclidean Distance')\n",
    "                #word2Vec_e = scores.word2Vec(documents_df,'Euclidean Distance')\n",
    "                #doc2Vec_e = scores.doc2Vec(documents_df,'Euclidean Distance')\n",
    "                #golVe_e = scores.golVe(documents_df,'Euclidean Distance')\n",
    "                tf_idf_e = scores.tf_idf(documents_df,'Euclidean Distance')\n",
    "\n",
    "\n",
    "                y['bert_c'][index_list[i]] = bert_c\n",
    "                #y['word2Vec_c'][index_list[i]] = word2Vec_c\n",
    "                #y['doc2Vec_c'][index_list[i]] = doc2Vec_c\n",
    "                #y['golVe_c'][index_list[i]] = golVe_c\n",
    "                y['tf_idf_c'][index_list[i]] = tf_idf_c\n",
    "                y['bert_e'][index_list[i]] = bert_e\n",
    "                #y['word2Vec_e'][index_list[i]] = word2Vec_e\n",
    "                #y['doc2Vec_e'][index_list[i]] = doc2Vec_e\n",
    "                #y['golVe_e'][index_list[i]] = golVe_e\n",
    "                y['tf_idf_e'][index_list[i]] = tf_idf_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>dateyear</th>\n",
       "      <th>quarter</th>\n",
       "      <th>Field3</th>\n",
       "      <th>bert_c</th>\n",
       "      <th>word2Vec_c</th>\n",
       "      <th>doc2Vec_c</th>\n",
       "      <th>golVe_c</th>\n",
       "      <th>tf_idf_c</th>\n",
       "      <th>bert_e</th>\n",
       "      <th>word2Vec_e</th>\n",
       "      <th>doc2Vec_e</th>\n",
       "      <th>golVe_e</th>\n",
       "      <th>tf_idf_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2007-05-30</td>\n",
       "      <td>4</td>\n",
       "      <td>AAR Corp. (NYSE:AIR) F3Q08 (Qtr End 02/29/08) ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2008-05-30</td>\n",
       "      <td>4</td>\n",
       "      <td>AAR CORP. (NYSE:AIR) F3Q09 (Qtr End 02/28/09) ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2012-05-30</td>\n",
       "      <td>4</td>\n",
       "      <td>AAR (NYSE:AIR) Q3 2013 Earnings Call March 19,...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2013-05-30</td>\n",
       "      <td>1</td>\n",
       "      <td>AAR Corp. (NYSE:AIR) Q4 2013 Earnings Call Jul...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2013-05-30</td>\n",
       "      <td>2</td>\n",
       "      <td>AAR (NYSE:AIR) Q1 2014 Earnings Call September...</td>\n",
       "      <td>0.917538</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.952115</td>\n",
       "      <td>6.09135</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.309466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2013-05-30</td>\n",
       "      <td>3</td>\n",
       "      <td>AAR (NYSE:AIR) Q2 2014 Earnings Call December ...</td>\n",
       "      <td>0.976104</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.95418</td>\n",
       "      <td>3.24289</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.302722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2013-05-30</td>\n",
       "      <td>4</td>\n",
       "      <td>AAR Corp (NYSE:AIR) F3Q2014 Earnings Conferenc...</td>\n",
       "      <td>0.96972</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.951132</td>\n",
       "      <td>3.66739</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.312627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2014-05-30</td>\n",
       "      <td>1</td>\n",
       "      <td>AAR Corporation (NYSE:AIR) Q4 2014 Earnings Co...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CIK    dateyear  quarter  \\\n",
       "0  0000001750  2007-05-30        4   \n",
       "1  0000001750  2008-05-30        4   \n",
       "2  0000001750  2012-05-30        4   \n",
       "3  0000001750  2013-05-30        1   \n",
       "4  0000001750  2013-05-30        2   \n",
       "5  0000001750  2013-05-30        3   \n",
       "6  0000001750  2013-05-30        4   \n",
       "7  0000001750  2014-05-30        1   \n",
       "\n",
       "                                              Field3    bert_c word2Vec_c  \\\n",
       "0  AAR Corp. (NYSE:AIR) F3Q08 (Qtr End 02/29/08) ...                        \n",
       "1  AAR CORP. (NYSE:AIR) F3Q09 (Qtr End 02/28/09) ...                        \n",
       "2  AAR (NYSE:AIR) Q3 2013 Earnings Call March 19,...                        \n",
       "3  AAR Corp. (NYSE:AIR) Q4 2013 Earnings Call Jul...                        \n",
       "4  AAR (NYSE:AIR) Q1 2014 Earnings Call September...  0.917538              \n",
       "5  AAR (NYSE:AIR) Q2 2014 Earnings Call December ...  0.976104              \n",
       "6  AAR Corp (NYSE:AIR) F3Q2014 Earnings Conferenc...   0.96972              \n",
       "7  AAR Corporation (NYSE:AIR) Q4 2014 Earnings Co...                        \n",
       "\n",
       "  doc2Vec_c golVe_c  tf_idf_c   bert_e word2Vec_e doc2Vec_e golVe_e  tf_idf_e  \n",
       "0                                                                              \n",
       "1                                                                              \n",
       "2                                                                              \n",
       "3                                                                              \n",
       "4                    0.952115  6.09135                               0.309466  \n",
       "5                     0.95418  3.24289                               0.302722  \n",
       "6                    0.951132  3.66739                               0.312627  \n",
       "7                                                                              "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrays2 = [['0000001750'], ['2007-05-30'],['4']]\n",
    "# i2 = pd.MultiIndex.from_arrays(arrays2, names=('CIK', 'dateyear','quarter'))\n",
    "# t2 = df_3.loc[i]['Field3']\n",
    "# t2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# per dateyear df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_dateyear = df_new_sorted3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_dateyear3 = df_per_dateyear[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_agg3 = lambda x: ' '.join(x)\n",
    "df_3 = df_per_dateyear3.groupby(['CIK','dateyear']).agg({'Field3':array_agg3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Field3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CIK</th>\n",
       "      <th>dateyear</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0000001750</th>\n",
       "      <th>2007-05-30</th>\n",
       "      <td>AAR Corp. (NYSE:AIR) F3Q08 (Qtr End 02/29/08) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-05-30</th>\n",
       "      <td>AAR CORP. (NYSE:AIR) F3Q09 (Qtr End 02/28/09) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-30</th>\n",
       "      <td>AAR (NYSE:AIR) Q3 2013 Earnings Call March 19,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-30</th>\n",
       "      <td>AAR Corp (NYSE:AIR) F3Q2014 Earnings Conferenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-30</th>\n",
       "      <td>AAR Corporation (NYSE:AIR) Q3 2015 Results Ear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  Field3\n",
       "CIK        dateyear                                                     \n",
       "0000001750 2007-05-30  AAR Corp. (NYSE:AIR) F3Q08 (Qtr End 02/29/08) ...\n",
       "           2008-05-30  AAR CORP. (NYSE:AIR) F3Q09 (Qtr End 02/28/09) ...\n",
       "           2012-05-30  AAR (NYSE:AIR) Q3 2013 Earnings Call March 19,...\n",
       "           2013-05-30  AAR Corp (NYSE:AIR) F3Q2014 Earnings Conferenc...\n",
       "           2014-05-30  AAR Corporation (NYSE:AIR) Q3 2015 Results Ear..."
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = df_3.reset_index(inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>dateyear</th>\n",
       "      <th>Field3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2007-05-30</td>\n",
       "      <td>AAR Corp. (NYSE:AIR) F3Q08 (Qtr End 02/29/08) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2008-05-30</td>\n",
       "      <td>AAR CORP. (NYSE:AIR) F3Q09 (Qtr End 02/28/09) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2012-05-30</td>\n",
       "      <td>AAR (NYSE:AIR) Q3 2013 Earnings Call March 19,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2013-05-30</td>\n",
       "      <td>AAR Corp (NYSE:AIR) F3Q2014 Earnings Conferenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2014-05-30</td>\n",
       "      <td>AAR Corporation (NYSE:AIR) Q3 2015 Results Ear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CIK    dateyear                                             Field3\n",
       "0  0000001750  2007-05-30  AAR Corp. (NYSE:AIR) F3Q08 (Qtr End 02/29/08) ...\n",
       "1  0000001750  2008-05-30  AAR CORP. (NYSE:AIR) F3Q09 (Qtr End 02/28/09) ...\n",
       "2  0000001750  2012-05-30  AAR (NYSE:AIR) Q3 2013 Earnings Call March 19,...\n",
       "3  0000001750  2013-05-30  AAR Corp (NYSE:AIR) F3Q2014 Earnings Conferenc...\n",
       "4  0000001750  2014-05-30  AAR Corporation (NYSE:AIR) Q3 2015 Results Ear..."
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score calculating logic per dateyear\n",
    "\n",
    "#z['Cosine_Similarity'] = \"\"\n",
    "#z['Euclidean_Distance'] = \"\"\n",
    "\n",
    "z['bert_c'] = \"\"\n",
    "z['word2Vec_c'] = \"\"\n",
    "z['doc2Vec_c'] = \"\"\n",
    "z['golVe_c'] = \"\"\n",
    "z['tf_idf_c'] = \"\"\n",
    "z['bert_e'] = \"\"\n",
    "z['word2Vec_e'] = \"\"\n",
    "z['doc2Vec_e'] = \"\"\n",
    "z['golVe_e'] = \"\"\n",
    "z['tf_idf_e'] = \"\"\n",
    "\n",
    "\n",
    "CIK_list_3 = list(set(z['CIK'].to_list()))\n",
    "\n",
    "for i in range(0,len(CIK_list_3)):\n",
    "    df_temp_cik_3 = z.loc[z['CIK'] == CIK_list_3[i]]\n",
    "    \n",
    "    dateyear_list_3 = list(set(df_temp_cik_3['dateyear'].to_list()))\n",
    "    \n",
    "    dateyear_year = []\n",
    "    for i in range(0,len(dateyear_list_3)):\n",
    "        dateyear_year.append(int(dateyear_list_3[i].split('-')[0]))\n",
    "        \n",
    "    dateyear_year = set(dateyear_year)\n",
    "    \n",
    "    index_list = df_temp_cik_3.index.tolist()\n",
    "\n",
    "    for i in range(1,len(df_temp_cik_3)):\n",
    "        current_year = int(df_temp_cik_3['dateyear'][i].split('-')[0])\n",
    "\n",
    "        \n",
    "        if current_year - 1 in dateyear_year:\n",
    "            documents_df = df_temp_cik_3.iloc[i-1:i+1,2].reset_index(drop = True).to_frame()\n",
    "            \n",
    "            # remove from\n",
    "            #cosine = score(documents_df,'Cosine Similarity')\n",
    "            #euclidean = score(documents_df,'Euclidean Distance')\n",
    "                \n",
    "            #z['Cosine_Similarity'][index_list[i]] = cosine\n",
    "            #z['Euclidean_Distance'][index_list[i]] = euclidean\n",
    "            # remove end\n",
    "            \n",
    "#             stop_words_l = stopwords.words('english')\n",
    "#             documents_df['Field3'] = \\\n",
    "#                 documents_df.documents.apply(lambda x: \\\n",
    "#                     ' '.join(re.sub(r'[^a-zA-Z]', ' ', w).lower() for w in\n",
    "#                     x.split() if re.sub(r'[^a-zA-Z]', ' ', w).lower()\n",
    "#                     not in stop_words_l))\n",
    "\n",
    "            bert_c = scores.bert(documents_df,'Cosine Similarity')\n",
    "            #word2Vec_c = scores.word2Vec(documents_df,'Cosine Similarity')\n",
    "            #doc2Vec_c = scores.doc2Vec(documents_df,'Cosine Similarity')\n",
    "            #golVe_c = scores.golVe(documents_df,'Cosine Similarity')\n",
    "            tf_idf_c = scores.tf_idf(documents_df,'Cosine Similarity')\n",
    "            bert_e = scores.bert(documents_df,'Euclidean Distance')\n",
    "            #word2Vec_e = scores.word2Vec(documents_df,'Euclidean Distance')\n",
    "            #doc2Vec_e = scores.doc2Vec(documents_df,'Euclidean Distance')\n",
    "            #golVe_e = scores.golVe(documents_df,'Euclidean Distance')\n",
    "            tf_idf_e = scores.tf_idf(documents_df,'Euclidean Distance')\n",
    "        \n",
    "        \n",
    "            z['bert_c'][index_list[i]] = bert_c\n",
    "            #z['word2Vec_c'][index_list[i]] = word2Vec_c\n",
    "            #z['doc2Vec_c'][index_list[i]] = doc2Vec_c\n",
    "            #z['golVe_c'][index_list[i]] = golVe_c\n",
    "            z['tf_idf_c'][index_list[i]] = tf_idf_c\n",
    "            z['bert_e'][index_list[i]] = bert_e\n",
    "            #z['word2Vec_e'][index_list[i]] = word2Vec_e\n",
    "            #z['doc2Vec_e'][index_list[i]] = doc2Vec_e\n",
    "            #z['golVe_e'][index_list[i]] = golVe_e\n",
    "            z['tf_idf_e'][index_list[i]] = tf_idf_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c\n",
    "# CIK_list_3\n",
    "# index_list\n",
    "# dateyear_list_3\n",
    "# print(dateyear_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>dateyear</th>\n",
       "      <th>Field3</th>\n",
       "      <th>bert_c</th>\n",
       "      <th>word2Vec_c</th>\n",
       "      <th>doc2Vec_c</th>\n",
       "      <th>golVe_c</th>\n",
       "      <th>tf_idf_c</th>\n",
       "      <th>bert_e</th>\n",
       "      <th>word2Vec_e</th>\n",
       "      <th>doc2Vec_e</th>\n",
       "      <th>golVe_e</th>\n",
       "      <th>tf_idf_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2007-05-30</td>\n",
       "      <td>AAR Corp. (NYSE:AIR) F3Q08 (Qtr End 02/29/08) ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2008-05-30</td>\n",
       "      <td>AAR CORP. (NYSE:AIR) F3Q09 (Qtr End 02/28/09) ...</td>\n",
       "      <td>0.941055</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.961488</td>\n",
       "      <td>5.20785</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.277532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2012-05-30</td>\n",
       "      <td>AAR (NYSE:AIR) Q3 2013 Earnings Call March 19,...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2013-05-30</td>\n",
       "      <td>AAR Corp (NYSE:AIR) F3Q2014 Earnings Conferenc...</td>\n",
       "      <td>0.960061</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.973371</td>\n",
       "      <td>4.23228</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.230775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>2014-05-30</td>\n",
       "      <td>AAR Corporation (NYSE:AIR) Q3 2015 Results Ear...</td>\n",
       "      <td>0.901177</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.947412</td>\n",
       "      <td>6.78751</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.32431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CIK    dateyear                                             Field3  \\\n",
       "0  0000001750  2007-05-30  AAR Corp. (NYSE:AIR) F3Q08 (Qtr End 02/29/08) ...   \n",
       "1  0000001750  2008-05-30  AAR CORP. (NYSE:AIR) F3Q09 (Qtr End 02/28/09) ...   \n",
       "2  0000001750  2012-05-30  AAR (NYSE:AIR) Q3 2013 Earnings Call March 19,...   \n",
       "3  0000001750  2013-05-30  AAR Corp (NYSE:AIR) F3Q2014 Earnings Conferenc...   \n",
       "4  0000001750  2014-05-30  AAR Corporation (NYSE:AIR) Q3 2015 Results Ear...   \n",
       "\n",
       "     bert_c word2Vec_c doc2Vec_c golVe_c  tf_idf_c   bert_e word2Vec_e  \\\n",
       "0                                                                        \n",
       "1  0.941055                               0.961488  5.20785              \n",
       "2                                                                        \n",
       "3  0.960061                               0.973371  4.23228              \n",
       "4  0.901177                               0.947412  6.78751              \n",
       "\n",
       "  doc2Vec_e golVe_e  tf_idf_e  \n",
       "0                              \n",
       "1                    0.277532  \n",
       "2                              \n",
       "3                    0.230775  \n",
       "4                     0.32431  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df.sort_values(by= [\"CIK\",\"fyear\",\"Month\",\"Day\"], kind=\"mergesort\", ascending=[True, True, True, True]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = sorted_df.dropna()\n",
    "clean_df = sorted_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = sorted_df[sorted_df['fyear'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
