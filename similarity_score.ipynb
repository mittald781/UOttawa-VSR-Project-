{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = pd.read_stata(\"./compustat_crsp_merged_1989_2019_identifier.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_database = database.sort_values(by=\"cik\", kind=\"mergesort\").reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_database['datayear'] = pd.DatetimeIndex(sorted_database['datadate']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>lpermno</th>\n",
       "      <th>lpermco</th>\n",
       "      <th>datadate</th>\n",
       "      <th>fyear</th>\n",
       "      <th>tic</th>\n",
       "      <th>cusip</th>\n",
       "      <th>conm</th>\n",
       "      <th>cik</th>\n",
       "      <th>sich</th>\n",
       "      <th>sic</th>\n",
       "      <th>datayear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001038</td>\n",
       "      <td>66413.0</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>1989-03-31</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>AEN.2</td>\n",
       "      <td>001669100</td>\n",
       "      <td>AMC ENTERTAINMENT INC -OLD</td>\n",
       "      <td></td>\n",
       "      <td>7830.0</td>\n",
       "      <td>7830</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001038</td>\n",
       "      <td>66413.0</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>1990-03-31</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>AEN.2</td>\n",
       "      <td>001669100</td>\n",
       "      <td>AMC ENTERTAINMENT INC -OLD</td>\n",
       "      <td></td>\n",
       "      <td>7830.0</td>\n",
       "      <td>7830</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001038</td>\n",
       "      <td>66413.0</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>1991-03-31</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>AEN.2</td>\n",
       "      <td>001669100</td>\n",
       "      <td>AMC ENTERTAINMENT INC -OLD</td>\n",
       "      <td></td>\n",
       "      <td>7830.0</td>\n",
       "      <td>7830</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001038</td>\n",
       "      <td>66413.0</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>1992-03-31</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>AEN.2</td>\n",
       "      <td>001669100</td>\n",
       "      <td>AMC ENTERTAINMENT INC -OLD</td>\n",
       "      <td></td>\n",
       "      <td>7830.0</td>\n",
       "      <td>7830</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001038</td>\n",
       "      <td>66413.0</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>1993-03-31</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>AEN.2</td>\n",
       "      <td>001669100</td>\n",
       "      <td>AMC ENTERTAINMENT INC -OLD</td>\n",
       "      <td></td>\n",
       "      <td>7830.0</td>\n",
       "      <td>7830</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204988</th>\n",
       "      <td>066336</td>\n",
       "      <td>89498.0</td>\n",
       "      <td>43502.0</td>\n",
       "      <td>2005-12-31</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>TSBA</td>\n",
       "      <td>89157H106</td>\n",
       "      <td>TOUCHSTONE BANKSHARES INC</td>\n",
       "      <td>0001821297</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>6020</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204989</th>\n",
       "      <td>066336</td>\n",
       "      <td>89498.0</td>\n",
       "      <td>43502.0</td>\n",
       "      <td>2006-12-31</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>TSBA</td>\n",
       "      <td>89157H106</td>\n",
       "      <td>TOUCHSTONE BANKSHARES INC</td>\n",
       "      <td>0001821297</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>6020</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204990</th>\n",
       "      <td>066336</td>\n",
       "      <td>89498.0</td>\n",
       "      <td>43502.0</td>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>TSBA</td>\n",
       "      <td>89157H106</td>\n",
       "      <td>TOUCHSTONE BANKSHARES INC</td>\n",
       "      <td>0001821297</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>6020</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204991</th>\n",
       "      <td>066336</td>\n",
       "      <td>89498.0</td>\n",
       "      <td>43502.0</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>TSBA</td>\n",
       "      <td>89157H106</td>\n",
       "      <td>TOUCHSTONE BANKSHARES INC</td>\n",
       "      <td>0001821297</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>6020</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204992</th>\n",
       "      <td>176828</td>\n",
       "      <td>18459.0</td>\n",
       "      <td>56685.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>CARE</td>\n",
       "      <td>146103106</td>\n",
       "      <td>CARTER BANKSHARES INC</td>\n",
       "      <td>0001829576</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>6020</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204993 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         gvkey  lpermno  lpermco   datadate   fyear    tic      cusip  \\\n",
       "0       001038  66413.0   6301.0 1989-03-31  1988.0  AEN.2  001669100   \n",
       "1       001038  66413.0   6301.0 1990-03-31  1989.0  AEN.2  001669100   \n",
       "2       001038  66413.0   6301.0 1991-03-31  1990.0  AEN.2  001669100   \n",
       "3       001038  66413.0   6301.0 1992-03-31  1991.0  AEN.2  001669100   \n",
       "4       001038  66413.0   6301.0 1993-03-31  1992.0  AEN.2  001669100   \n",
       "...        ...      ...      ...        ...     ...    ...        ...   \n",
       "204988  066336  89498.0  43502.0 2005-12-31  2005.0   TSBA  89157H106   \n",
       "204989  066336  89498.0  43502.0 2006-12-31  2006.0   TSBA  89157H106   \n",
       "204990  066336  89498.0  43502.0 2007-12-31  2007.0   TSBA  89157H106   \n",
       "204991  066336  89498.0  43502.0 2008-12-31  2008.0   TSBA  89157H106   \n",
       "204992  176828  18459.0  56685.0 2019-12-31  2019.0   CARE  146103106   \n",
       "\n",
       "                              conm         cik    sich   sic  datayear  \n",
       "0       AMC ENTERTAINMENT INC -OLD              7830.0  7830      1989  \n",
       "1       AMC ENTERTAINMENT INC -OLD              7830.0  7830      1990  \n",
       "2       AMC ENTERTAINMENT INC -OLD              7830.0  7830      1991  \n",
       "3       AMC ENTERTAINMENT INC -OLD              7830.0  7830      1992  \n",
       "4       AMC ENTERTAINMENT INC -OLD              7830.0  7830      1993  \n",
       "...                            ...         ...     ...   ...       ...  \n",
       "204988   TOUCHSTONE BANKSHARES INC  0001821297  6020.0  6020      2005  \n",
       "204989   TOUCHSTONE BANKSHARES INC  0001821297  6020.0  6020      2006  \n",
       "204990   TOUCHSTONE BANKSHARES INC  0001821297  6020.0  6020      2007  \n",
       "204991   TOUCHSTONE BANKSHARES INC  0001821297  6020.0  6020      2008  \n",
       "204992       CARTER BANKSHARES INC  0001829576  6020.0  6020      2019  \n",
       "\n",
       "[204993 rows x 12 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204993"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5922\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sorted_database)):\n",
    "    if len(sorted_database['cik'][i])!=0:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDict = {}\n",
    "for i in range(5922,len(sorted_database)):\n",
    "    #storing this first CIK as previous CIK\n",
    "    prev = sorted_database['cik'][i]\n",
    "    #creating empty list for datadates over 1989-2021 period\n",
    "    l = [None] * 33\n",
    "    while i<len(sorted_database) and sorted_database['cik'][i] == prev:\n",
    "        year = sorted_database['datayear'][i]\n",
    "        sample_year = year\n",
    "        l[year-1989] = sorted_database['datadate'][i]\n",
    "        sample_datadate = sorted_database['datadate'][i]\n",
    "        i += 1\n",
    "        for j in range(len(l)):\n",
    "            if l[j] == None:\n",
    "                yr = j + 1989\n",
    "                mnth = sample_datadate.month\n",
    "                dy = sample_datadate.day\n",
    "                # Create the Timestamp object\n",
    "                ts = pd.Timestamp(year = yr, month = mnth, day = dy - 1, hour = 0, minute = 0, second = 0)\n",
    "                l[j] = ts\n",
    "    myDict[prev] = l\n",
    "    i -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19511"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(myDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('1989-12-30 00:00:00'),\n",
       " Timestamp('1990-12-30 00:00:00'),\n",
       " Timestamp('1991-12-30 00:00:00'),\n",
       " Timestamp('1992-12-30 00:00:00'),\n",
       " Timestamp('1993-12-30 00:00:00'),\n",
       " Timestamp('1994-12-30 00:00:00'),\n",
       " Timestamp('1995-12-30 00:00:00'),\n",
       " Timestamp('1996-12-30 00:00:00'),\n",
       " Timestamp('1997-12-30 00:00:00'),\n",
       " Timestamp('1998-12-30 00:00:00'),\n",
       " Timestamp('1999-12-30 00:00:00'),\n",
       " Timestamp('2000-12-30 00:00:00'),\n",
       " Timestamp('2001-12-30 00:00:00'),\n",
       " Timestamp('2002-12-30 00:00:00'),\n",
       " Timestamp('2003-12-30 00:00:00'),\n",
       " Timestamp('2004-12-30 00:00:00'),\n",
       " Timestamp('2005-12-30 00:00:00'),\n",
       " Timestamp('2006-12-30 00:00:00'),\n",
       " Timestamp('2007-12-30 00:00:00'),\n",
       " Timestamp('2008-12-31 00:00:00'),\n",
       " Timestamp('2009-12-30 00:00:00'),\n",
       " Timestamp('2010-12-30 00:00:00'),\n",
       " Timestamp('2011-12-30 00:00:00'),\n",
       " Timestamp('2012-12-30 00:00:00'),\n",
       " Timestamp('2013-12-30 00:00:00'),\n",
       " Timestamp('2014-12-30 00:00:00'),\n",
       " Timestamp('2015-12-30 00:00:00'),\n",
       " Timestamp('2016-12-30 00:00:00'),\n",
       " Timestamp('2017-12-30 00:00:00'),\n",
       " Timestamp('2018-12-30 00:00:00'),\n",
       " Timestamp('2019-12-30 00:00:00'),\n",
       " Timestamp('2020-12-30 00:00:00'),\n",
       " Timestamp('2021-12-30 00:00:00')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDict['0001821297']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv',encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229956"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(inplace= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229741"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df) #checking how many unique are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Field1</th>\n",
       "      <th>Field2_Text</th>\n",
       "      <th>Field3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...</td>\n",
       "      <td>Jun.  1, 2020  2:30 PM ET</td>\n",
       "      <td>EOG Resources, Inc. (EOG)</td>\n",
       "      <td>EOG Resources, Inc. (NYSE:EOG) AllianceBernste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...</td>\n",
       "      <td>May 20, 2020  5:35 PM ET</td>\n",
       "      <td>Eaton Vance Corp. (EV)</td>\n",
       "      <td>Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...</td>\n",
       "      <td>May  8, 2020  5:25 PM ET</td>\n",
       "      <td>Whitestone REIT (WSR)</td>\n",
       "      <td>Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Applied Materials Inc (AMAT) CEO Gary Dickerso...</td>\n",
       "      <td>May 30, 2020  1:22 AM ET</td>\n",
       "      <td>Applied Materials, Inc. (AMAT)</td>\n",
       "      <td>Applied Materials Inc (NASDAQ:AMAT)  2020 Bern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Garrett Motion Inc. (GTX) CEO Olivier Rabiller...</td>\n",
       "      <td>May 11, 2020  5:16 PM ET</td>\n",
       "      <td>Garrett Motion Inc. (GTX)</td>\n",
       "      <td>Start Time: 08:30 January  1, 0000  9:26 AM ET...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229736</th>\n",
       "      <td>Memorial Resource Development's (MRD) CEO John...</td>\n",
       "      <td>May  6, 2015  9:50 PM ET</td>\n",
       "      <td>Memorial Resource Development Corp. (MRD)</td>\n",
       "      <td>Memorial Resource Development Corp (NASDAQ:MRD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229737</th>\n",
       "      <td>Intersect ENT's (XENT) CEO Lisa Earnhardt on Q...</td>\n",
       "      <td>May  6, 2015  9:48 PM ET</td>\n",
       "      <td>Intersect ENT, Inc. (XENT)</td>\n",
       "      <td>Intersect ENT, Inc. (NASDAQ:XENT) Q1 2015 Earn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229738</th>\n",
       "      <td>Paycom Software's (PAYC) CEO Chad Richison on ...</td>\n",
       "      <td>May  6, 2015  9:46 PM ET</td>\n",
       "      <td>Paycom Software, Inc. (PAYC)</td>\n",
       "      <td>Paycom Software Inc. (NYSE:PAYC) Q1 2015 Earni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229739</th>\n",
       "      <td>Cerulean Pharma's (CERU) CEO Chris Guiffre Dis...</td>\n",
       "      <td>May  6, 2015  9:46 PM ET</td>\n",
       "      <td>DarÃ© Bioscience, Inc. (DARE)</td>\n",
       "      <td>Cerulean Pharma Inc. (CERU) Q1 2015 Earnings C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229740</th>\n",
       "      <td>Powell Industries' (POWL) CEO Mike Lucas on Q2...</td>\n",
       "      <td>May  6, 2015  9:37 PM ET</td>\n",
       "      <td>Powell Industries, Inc. (POWL)</td>\n",
       "      <td>Powell Industries, Inc. (NASDAQ:POWL) Q2 2015 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229741 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  \\\n",
       "0       EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...   \n",
       "1       Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...   \n",
       "2       Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...   \n",
       "3       Applied Materials Inc (AMAT) CEO Gary Dickerso...   \n",
       "4       Garrett Motion Inc. (GTX) CEO Olivier Rabiller...   \n",
       "...                                                   ...   \n",
       "229736  Memorial Resource Development's (MRD) CEO John...   \n",
       "229737  Intersect ENT's (XENT) CEO Lisa Earnhardt on Q...   \n",
       "229738  Paycom Software's (PAYC) CEO Chad Richison on ...   \n",
       "229739  Cerulean Pharma's (CERU) CEO Chris Guiffre Dis...   \n",
       "229740  Powell Industries' (POWL) CEO Mike Lucas on Q2...   \n",
       "\n",
       "                           Field1                                Field2_Text  \\\n",
       "0       Jun.  1, 2020  2:30 PM ET                  EOG Resources, Inc. (EOG)   \n",
       "1        May 20, 2020  5:35 PM ET                     Eaton Vance Corp. (EV)   \n",
       "2        May  8, 2020  5:25 PM ET                      Whitestone REIT (WSR)   \n",
       "3        May 30, 2020  1:22 AM ET             Applied Materials, Inc. (AMAT)   \n",
       "4        May 11, 2020  5:16 PM ET                  Garrett Motion Inc. (GTX)   \n",
       "...                           ...                                        ...   \n",
       "229736   May  6, 2015  9:50 PM ET  Memorial Resource Development Corp. (MRD)   \n",
       "229737   May  6, 2015  9:48 PM ET                 Intersect ENT, Inc. (XENT)   \n",
       "229738   May  6, 2015  9:46 PM ET               Paycom Software, Inc. (PAYC)   \n",
       "229739   May  6, 2015  9:46 PM ET              DarÃ© Bioscience, Inc. (DARE)   \n",
       "229740   May  6, 2015  9:37 PM ET             Powell Industries, Inc. (POWL)   \n",
       "\n",
       "                                                   Field3  \n",
       "0       EOG Resources, Inc. (NYSE:EOG) AllianceBernste...  \n",
       "1       Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...  \n",
       "2       Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...  \n",
       "3       Applied Materials Inc (NASDAQ:AMAT)  2020 Bern...  \n",
       "4       Start Time: 08:30 January  1, 0000  9:26 AM ET...  \n",
       "...                                                   ...  \n",
       "229736  Memorial Resource Development Corp (NASDAQ:MRD...  \n",
       "229737  Intersect ENT, Inc. (NASDAQ:XENT) Q1 2015 Earn...  \n",
       "229738  Paycom Software Inc. (NYSE:PAYC) Q1 2015 Earni...  \n",
       "229739  Cerulean Pharma Inc. (CERU) Q1 2015 Earnings C...  \n",
       "229740  Powell Industries, Inc. (NASDAQ:POWL) Q2 2015 ...  \n",
       "\n",
       "[229741 rows x 4 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_name = df['Field2_Text']    # creating a list of company names and their tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting tickers\n",
    "tickers = []\n",
    "Deleted_i = []\n",
    "for i in range(229741):\n",
    "    try:\n",
    "        ticker = com_name[i][com_name[i].find(\"(\")+1:com_name[i].find(\")\")]\n",
    "    except:\n",
    "        Deleted_i.append(i)\n",
    "    tickers.append(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tickers'] = tickers         # creating a new column in dataframe of only tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tickers'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating company names like we did for tickers\n",
    "com_names = []\n",
    "del_i = []\n",
    "for i in range(len(com_name)):\n",
    "    try:\n",
    "        name = com_name[i][0:com_name[i].find(\"(\")-1]\n",
    "    except:\n",
    "        del_i.append(i)\n",
    "    com_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['company_names_seekingalpha'] = com_names #creating a new column of company names from seeking alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cikandticker = database[['cik', 'tic']] #creating a subdataframe of only company name and tickers\n",
    "#here tickers are the link between the company names from seeking alpha and company names from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = database[['cik', 'tic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204993"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "cikandticker.drop_duplicates(inplace = True) #deduplication of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>tic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000730052</td>\n",
       "      <td>ANTQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000001750</td>\n",
       "      <td>AIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0000313368</td>\n",
       "      <td>ABSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0000702511</td>\n",
       "      <td>ACSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0000002134</td>\n",
       "      <td>6927B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204986</th>\n",
       "      <td>0001707210</td>\n",
       "      <td>NMCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204988</th>\n",
       "      <td>0001739445</td>\n",
       "      <td>ACA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204990</th>\n",
       "      <td>0001720161</td>\n",
       "      <td>CTRM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204991</th>\n",
       "      <td>0001280776</td>\n",
       "      <td>IMUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204992</th>\n",
       "      <td>0000921114</td>\n",
       "      <td>ARMP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20518 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               cik    tic\n",
       "0       0000730052   ANTQ\n",
       "1       0000001750    AIR\n",
       "32      0000313368   ABSI\n",
       "38      0000702511   ACSE\n",
       "44      0000002134  6927B\n",
       "...            ...    ...\n",
       "204986  0001707210   NMCI\n",
       "204988  0001739445    ACA\n",
       "204990  0001720161   CTRM\n",
       "204991  0001280776   IMUX\n",
       "204992  0000921114   ARMP\n",
       "\n",
       "[20518 rows x 2 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cikandticker[['cik','tic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting company names from the database which have the same ticker as that of our original data from seeking alpha\n",
    "ciks = []\n",
    "for ticker in tickers:\n",
    "    cik = cikandticker.loc[cikandticker['tic'] == ticker, 'cik']\n",
    "    #print(company)\n",
    "    try: #using try and except to avoid any errors when the company name is missing due to some missing values in data\n",
    "        ciks.append(cik.iloc[0])\n",
    "    except:\n",
    "        ciks.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CIK'] = ciks #creating a new column of the company names from database to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "conameandticker = database[['conm', 'tic']] #creating a subdataframe of only company name and tickers\n",
    "#here tickers are the link between the company names from seeking alpha and company names from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "conameandticker.drop_duplicates(inplace = True) #deduplication of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conm</th>\n",
       "      <th>tic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.A. IMPORTING CO INC</td>\n",
       "      <td>ANTQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>AIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ABS INDUSTRIES INC</td>\n",
       "      <td>ABSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ACS ENTERPRISES INC</td>\n",
       "      <td>ACSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ACS INDUSTRIES INC</td>\n",
       "      <td>6927B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204986</th>\n",
       "      <td>NAVIOS MARITIME CONTAINERS</td>\n",
       "      <td>NMCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204988</th>\n",
       "      <td>ARCOSA INC</td>\n",
       "      <td>ACA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204990</th>\n",
       "      <td>CASTOR MARITIME INC</td>\n",
       "      <td>CTRM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204991</th>\n",
       "      <td>IMMUNIC INC</td>\n",
       "      <td>IMUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204992</th>\n",
       "      <td>ARMATA PHARMACEUTICALS INC</td>\n",
       "      <td>ARMP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20518 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              conm    tic\n",
       "0            A.A. IMPORTING CO INC   ANTQ\n",
       "1                         AAR CORP    AIR\n",
       "32              ABS INDUSTRIES INC   ABSI\n",
       "38             ACS ENTERPRISES INC   ACSE\n",
       "44              ACS INDUSTRIES INC  6927B\n",
       "...                            ...    ...\n",
       "204986  NAVIOS MARITIME CONTAINERS   NMCI\n",
       "204988                  ARCOSA INC    ACA\n",
       "204990         CASTOR MARITIME INC   CTRM\n",
       "204991                 IMMUNIC INC   IMUX\n",
       "204992  ARMATA PHARMACEUTICALS INC   ARMP\n",
       "\n",
       "[20518 rows x 2 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conameandticker[['conm','tic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting company names from the database which have the same ticker as that of our original data from seeking alpha\n",
    "companies = []\n",
    "for ticker in tickers:\n",
    "    company = conameandticker.loc[conameandticker['tic'] == ticker, 'conm']\n",
    "    #print(company)\n",
    "    try: #using try and except to avoid any errors when the company name is missing due to some missing values in data\n",
    "        companies.append(company.iloc[0])\n",
    "    except:\n",
    "        companies.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['company_names_database'] = companies #creating a new column of the company names from database to compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DIVYANSHU\\anaconda3\\Scripts\\conda-script.py\", line 11, in <module>\n",
      "    from conda.cli import main\n",
      "ModuleNotFoundError: No module named 'conda'\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge python-levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "#if warning comes then use the below command in Anaconda Prompt\n",
    "#conda install -c conda-forge python-levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the scores after fuzzy matching between company names from two sources i.e seeking alpha and database\n",
    "scores = []\n",
    "for i,j in zip(df.company_names_seekingalpha,df.company_names_database):\n",
    "    score = fuzz.token_set_ratio(i,j)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['similarity_scores'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "dates = []\n",
    "months = []\n",
    "for i in range(len(df)):\n",
    "    datetime = df['Field1'][i]\n",
    "    month = datetime[0:3].strip()\n",
    "    idx = datetime.find(',')\n",
    "    date = datetime[4:idx].strip()\n",
    "    year = datetime[idx+1:idx+6].strip()\n",
    "    years.append(year)\n",
    "    months.append(month)\n",
    "    dates.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year'] = years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Month'] = months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Day'] = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toint(month):\n",
    "    if month == \"Jan\":\n",
    "        return 1\n",
    "    elif month == \"Feb\":\n",
    "        return 2\n",
    "    elif month == \"Mar\":\n",
    "        return 3\n",
    "    elif month == \"Apr\":\n",
    "        return 4\n",
    "    elif month == \"May\":\n",
    "        return 5\n",
    "    elif month == \"Jun\":\n",
    "        return 6\n",
    "    elif month == \"Jul\":\n",
    "        return 7\n",
    "    elif month == \"Aug\":\n",
    "        return 8\n",
    "    elif month == \"Sep\":\n",
    "        return 9\n",
    "    elif month == \"Oct\":\n",
    "        return 10\n",
    "    elif month == \"Nov\":\n",
    "        return 11\n",
    "    else:\n",
    "        return 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "calldict = {}\n",
    "nonevalues = []\n",
    "for i in range(len(df)):\n",
    "    cik = df['CIK'][i]\n",
    "    if cik==None:\n",
    "        continue\n",
    "    year = int(df['Year'][i])\n",
    "    try:\n",
    "        timestamp = myDict[cik][year-1989]\n",
    "        datadate = timestamp.day\n",
    "        datamonth = timestamp.month\n",
    "        calldate = int(df['Day'][i])\n",
    "        callmonth = toint(df['Month'][i])\n",
    "        yr = year\n",
    "        if callmonth < datamonth:\n",
    "            yr = year - 1\n",
    "        elif callmonth > datamonth:\n",
    "            yr = year\n",
    "        elif callmonth == datamonth:\n",
    "            if calldate <= datadate:\n",
    "                yr = year - 1\n",
    "            else:\n",
    "                yr = year\n",
    "        if cik in calldict.keys():\n",
    "            calldict[cik][yr-1989] += 1\n",
    "        else:\n",
    "            l = [0]*33\n",
    "            l[yr-1989] += 1\n",
    "            calldict[cik] = l\n",
    "    except:\n",
    "        nonevalues.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229740"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5837"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(calldict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "concalldata = pd.DataFrame.from_dict(calldict, orient ='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000821189</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000350797</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001175535</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000006951</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001617406</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000754009</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001007019</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001505823</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001448301</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001063259</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5837 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0   1   2   3   4   5   6   7   8   9   ...  23  24  25  26  27  \\\n",
       "0000821189   0   0   0   0   0   0   0   0   0   0  ...  12   5  10   6   6   \n",
       "0000350797   0   0   0   0   0   0   0   0   0   0  ...   6   5   6   7   6   \n",
       "0001175535   0   0   0   0   0   0   0   0   0   0  ...   4   4   6   6   6   \n",
       "0000006951   0   0   0   0   0   0   0   0   0   0  ...   9  11   5   7   6   \n",
       "0001617406   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   5   \n",
       "...         ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..   \n",
       "0000754009   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "0001007019   0   0   0   0   0   0   0   0   0   0  ...   0   0   1   0   0   \n",
       "0001505823   0   0   0   0   0   0   0   0   0   0  ...   0   0   1   0   0   \n",
       "0001448301   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   1   0   \n",
       "0001063259   0   0   0   0   0   0   0   0   0   0  ...   0   0   1   0   0   \n",
       "\n",
       "            28  29  30  31  32  \n",
       "0000821189  11  13  10   0   0  \n",
       "0000350797   7   8   6   0   0  \n",
       "0001175535   7   8   5   0   0  \n",
       "0000006951  10   9  15   0   0  \n",
       "0001617406   7   8   5   0   0  \n",
       "...         ..  ..  ..  ..  ..  \n",
       "0000754009   0   0   0   0   0  \n",
       "0001007019   0   0   0   0   0  \n",
       "0001505823   0   0   0   0   0  \n",
       "0001448301   0   0   0   0   0  \n",
       "0001063259   0   0   0   0   0  \n",
       "\n",
       "[5837 rows x 33 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concalldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nonevalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Field1</th>\n",
       "      <th>Field2_Text</th>\n",
       "      <th>Field3</th>\n",
       "      <th>tickers</th>\n",
       "      <th>company_names_seekingalpha</th>\n",
       "      <th>CIK</th>\n",
       "      <th>company_names_database</th>\n",
       "      <th>similarity_scores</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...</td>\n",
       "      <td>Jun.  1, 2020  2:30 PM ET</td>\n",
       "      <td>EOG Resources, Inc. (EOG)</td>\n",
       "      <td>EOG Resources, Inc. (NYSE:EOG) AllianceBernste...</td>\n",
       "      <td>EOG</td>\n",
       "      <td>EOG Resources, Inc.</td>\n",
       "      <td>0000821189</td>\n",
       "      <td>EOG RESOURCES INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jun</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...</td>\n",
       "      <td>May 20, 2020  5:35 PM ET</td>\n",
       "      <td>Eaton Vance Corp. (EV)</td>\n",
       "      <td>Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...</td>\n",
       "      <td>EV</td>\n",
       "      <td>Eaton Vance Corp.</td>\n",
       "      <td>0000350797</td>\n",
       "      <td>EATON VANCE CORP</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...</td>\n",
       "      <td>May  8, 2020  5:25 PM ET</td>\n",
       "      <td>Whitestone REIT (WSR)</td>\n",
       "      <td>Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...</td>\n",
       "      <td>WSR</td>\n",
       "      <td>Whitestone REIT</td>\n",
       "      <td>0001175535</td>\n",
       "      <td>WHITESTONE REIT</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Applied Materials Inc (AMAT) CEO Gary Dickerso...</td>\n",
       "      <td>May 30, 2020  1:22 AM ET</td>\n",
       "      <td>Applied Materials, Inc. (AMAT)</td>\n",
       "      <td>Applied Materials Inc (NASDAQ:AMAT)  2020 Bern...</td>\n",
       "      <td>AMAT</td>\n",
       "      <td>Applied Materials, Inc.</td>\n",
       "      <td>0000006951</td>\n",
       "      <td>APPLIED MATERIALS INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Garrett Motion Inc. (GTX) CEO Olivier Rabiller...</td>\n",
       "      <td>May 11, 2020  5:16 PM ET</td>\n",
       "      <td>Garrett Motion Inc. (GTX)</td>\n",
       "      <td>Start Time: 08:30 January  1, 0000  9:26 AM ET...</td>\n",
       "      <td>GTX</td>\n",
       "      <td>Garrett Motion Inc.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...   \n",
       "1  Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...   \n",
       "2  Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...   \n",
       "3  Applied Materials Inc (AMAT) CEO Gary Dickerso...   \n",
       "4  Garrett Motion Inc. (GTX) CEO Olivier Rabiller...   \n",
       "\n",
       "                      Field1                     Field2_Text  \\\n",
       "0  Jun.  1, 2020  2:30 PM ET       EOG Resources, Inc. (EOG)   \n",
       "1   May 20, 2020  5:35 PM ET          Eaton Vance Corp. (EV)   \n",
       "2   May  8, 2020  5:25 PM ET           Whitestone REIT (WSR)   \n",
       "3   May 30, 2020  1:22 AM ET  Applied Materials, Inc. (AMAT)   \n",
       "4   May 11, 2020  5:16 PM ET       Garrett Motion Inc. (GTX)   \n",
       "\n",
       "                                              Field3 tickers  \\\n",
       "0  EOG Resources, Inc. (NYSE:EOG) AllianceBernste...     EOG   \n",
       "1  Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...      EV   \n",
       "2  Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...     WSR   \n",
       "3  Applied Materials Inc (NASDAQ:AMAT)  2020 Bern...    AMAT   \n",
       "4  Start Time: 08:30 January  1, 0000  9:26 AM ET...     GTX   \n",
       "\n",
       "  company_names_seekingalpha         CIK company_names_database  \\\n",
       "0        EOG Resources, Inc.  0000821189      EOG RESOURCES INC   \n",
       "1          Eaton Vance Corp.  0000350797       EATON VANCE CORP   \n",
       "2            Whitestone REIT  0001175535        WHITESTONE REIT   \n",
       "3    Applied Materials, Inc.  0000006951  APPLIED MATERIALS INC   \n",
       "4        Garrett Motion Inc.        None                   None   \n",
       "\n",
       "   similarity_scores  Year Month Day  \n",
       "0                100  2020   Jun   1  \n",
       "1                100  2020   May  20  \n",
       "2                100  2020   May   8  \n",
       "3                100  2020   May  30  \n",
       "4                  0  2020   May  11  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229741"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Field1</th>\n",
       "      <th>Field2_Text</th>\n",
       "      <th>Field3</th>\n",
       "      <th>tickers</th>\n",
       "      <th>company_names_seekingalpha</th>\n",
       "      <th>CIK</th>\n",
       "      <th>company_names_database</th>\n",
       "      <th>similarity_scores</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...</td>\n",
       "      <td>Jun.  1, 2020  2:30 PM ET</td>\n",
       "      <td>EOG Resources, Inc. (EOG)</td>\n",
       "      <td>EOG Resources, Inc. (NYSE:EOG) AllianceBernste...</td>\n",
       "      <td>EOG</td>\n",
       "      <td>EOG Resources, Inc.</td>\n",
       "      <td>0000821189</td>\n",
       "      <td>EOG RESOURCES INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jun</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...</td>\n",
       "      <td>May 20, 2020  5:35 PM ET</td>\n",
       "      <td>Eaton Vance Corp. (EV)</td>\n",
       "      <td>Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...</td>\n",
       "      <td>EV</td>\n",
       "      <td>Eaton Vance Corp.</td>\n",
       "      <td>0000350797</td>\n",
       "      <td>EATON VANCE CORP</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...</td>\n",
       "      <td>May  8, 2020  5:25 PM ET</td>\n",
       "      <td>Whitestone REIT (WSR)</td>\n",
       "      <td>Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...</td>\n",
       "      <td>WSR</td>\n",
       "      <td>Whitestone REIT</td>\n",
       "      <td>0001175535</td>\n",
       "      <td>WHITESTONE REIT</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Applied Materials Inc (AMAT) CEO Gary Dickerso...</td>\n",
       "      <td>May 30, 2020  1:22 AM ET</td>\n",
       "      <td>Applied Materials, Inc. (AMAT)</td>\n",
       "      <td>Applied Materials Inc (NASDAQ:AMAT)  2020 Bern...</td>\n",
       "      <td>AMAT</td>\n",
       "      <td>Applied Materials, Inc.</td>\n",
       "      <td>0000006951</td>\n",
       "      <td>APPLIED MATERIALS INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Garrett Motion Inc. (GTX) CEO Olivier Rabiller...</td>\n",
       "      <td>May 11, 2020  5:16 PM ET</td>\n",
       "      <td>Garrett Motion Inc. (GTX)</td>\n",
       "      <td>Start Time: 08:30 January  1, 0000  9:26 AM ET...</td>\n",
       "      <td>GTX</td>\n",
       "      <td>Garrett Motion Inc.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229736</th>\n",
       "      <td>Memorial Resource Development's (MRD) CEO John...</td>\n",
       "      <td>May  6, 2015  9:50 PM ET</td>\n",
       "      <td>Memorial Resource Development Corp. (MRD)</td>\n",
       "      <td>Memorial Resource Development Corp (NASDAQ:MRD...</td>\n",
       "      <td>MRD</td>\n",
       "      <td>Memorial Resource Development Corp.</td>\n",
       "      <td>0001599222</td>\n",
       "      <td>MEMORIAL RESOURCE DEV CORP</td>\n",
       "      <td>92</td>\n",
       "      <td>2015</td>\n",
       "      <td>May</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229737</th>\n",
       "      <td>Intersect ENT's (XENT) CEO Lisa Earnhardt on Q...</td>\n",
       "      <td>May  6, 2015  9:48 PM ET</td>\n",
       "      <td>Intersect ENT, Inc. (XENT)</td>\n",
       "      <td>Intersect ENT, Inc. (NASDAQ:XENT) Q1 2015 Earn...</td>\n",
       "      <td>XENT</td>\n",
       "      <td>Intersect ENT, Inc.</td>\n",
       "      <td>0001271214</td>\n",
       "      <td>INTERSECT ENT INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2015</td>\n",
       "      <td>May</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229738</th>\n",
       "      <td>Paycom Software's (PAYC) CEO Chad Richison on ...</td>\n",
       "      <td>May  6, 2015  9:46 PM ET</td>\n",
       "      <td>Paycom Software, Inc. (PAYC)</td>\n",
       "      <td>Paycom Software Inc. (NYSE:PAYC) Q1 2015 Earni...</td>\n",
       "      <td>PAYC</td>\n",
       "      <td>Paycom Software, Inc.</td>\n",
       "      <td>0001590955</td>\n",
       "      <td>PAYCOM SOFTWARE INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2015</td>\n",
       "      <td>May</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229739</th>\n",
       "      <td>Cerulean Pharma's (CERU) CEO Chris Guiffre Dis...</td>\n",
       "      <td>May  6, 2015  9:46 PM ET</td>\n",
       "      <td>DarÃ© Bioscience, Inc. (DARE)</td>\n",
       "      <td>Cerulean Pharma Inc. (CERU) Q1 2015 Earnings C...</td>\n",
       "      <td>DARE</td>\n",
       "      <td>DarÃ© Bioscience, Inc.</td>\n",
       "      <td>0001701808</td>\n",
       "      <td>DARE BIOSCIENCE INC</td>\n",
       "      <td>97</td>\n",
       "      <td>2015</td>\n",
       "      <td>May</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229740</th>\n",
       "      <td>Powell Industries' (POWL) CEO Mike Lucas on Q2...</td>\n",
       "      <td>May  6, 2015  9:37 PM ET</td>\n",
       "      <td>Powell Industries, Inc. (POWL)</td>\n",
       "      <td>Powell Industries, Inc. (NASDAQ:POWL) Q2 2015 ...</td>\n",
       "      <td>POWL</td>\n",
       "      <td>Powell Industries, Inc.</td>\n",
       "      <td>0000080420</td>\n",
       "      <td>POWELL INDUSTRIES INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2015</td>\n",
       "      <td>May</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229741 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  \\\n",
       "0       EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...   \n",
       "1       Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...   \n",
       "2       Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...   \n",
       "3       Applied Materials Inc (AMAT) CEO Gary Dickerso...   \n",
       "4       Garrett Motion Inc. (GTX) CEO Olivier Rabiller...   \n",
       "...                                                   ...   \n",
       "229736  Memorial Resource Development's (MRD) CEO John...   \n",
       "229737  Intersect ENT's (XENT) CEO Lisa Earnhardt on Q...   \n",
       "229738  Paycom Software's (PAYC) CEO Chad Richison on ...   \n",
       "229739  Cerulean Pharma's (CERU) CEO Chris Guiffre Dis...   \n",
       "229740  Powell Industries' (POWL) CEO Mike Lucas on Q2...   \n",
       "\n",
       "                           Field1                                Field2_Text  \\\n",
       "0       Jun.  1, 2020  2:30 PM ET                  EOG Resources, Inc. (EOG)   \n",
       "1        May 20, 2020  5:35 PM ET                     Eaton Vance Corp. (EV)   \n",
       "2        May  8, 2020  5:25 PM ET                      Whitestone REIT (WSR)   \n",
       "3        May 30, 2020  1:22 AM ET             Applied Materials, Inc. (AMAT)   \n",
       "4        May 11, 2020  5:16 PM ET                  Garrett Motion Inc. (GTX)   \n",
       "...                           ...                                        ...   \n",
       "229736   May  6, 2015  9:50 PM ET  Memorial Resource Development Corp. (MRD)   \n",
       "229737   May  6, 2015  9:48 PM ET                 Intersect ENT, Inc. (XENT)   \n",
       "229738   May  6, 2015  9:46 PM ET               Paycom Software, Inc. (PAYC)   \n",
       "229739   May  6, 2015  9:46 PM ET              DarÃ© Bioscience, Inc. (DARE)   \n",
       "229740   May  6, 2015  9:37 PM ET             Powell Industries, Inc. (POWL)   \n",
       "\n",
       "                                                   Field3 tickers  \\\n",
       "0       EOG Resources, Inc. (NYSE:EOG) AllianceBernste...     EOG   \n",
       "1       Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...      EV   \n",
       "2       Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...     WSR   \n",
       "3       Applied Materials Inc (NASDAQ:AMAT)  2020 Bern...    AMAT   \n",
       "4       Start Time: 08:30 January  1, 0000  9:26 AM ET...     GTX   \n",
       "...                                                   ...     ...   \n",
       "229736  Memorial Resource Development Corp (NASDAQ:MRD...     MRD   \n",
       "229737  Intersect ENT, Inc. (NASDAQ:XENT) Q1 2015 Earn...    XENT   \n",
       "229738  Paycom Software Inc. (NYSE:PAYC) Q1 2015 Earni...    PAYC   \n",
       "229739  Cerulean Pharma Inc. (CERU) Q1 2015 Earnings C...    DARE   \n",
       "229740  Powell Industries, Inc. (NASDAQ:POWL) Q2 2015 ...    POWL   \n",
       "\n",
       "                 company_names_seekingalpha         CIK  \\\n",
       "0                       EOG Resources, Inc.  0000821189   \n",
       "1                         Eaton Vance Corp.  0000350797   \n",
       "2                           Whitestone REIT  0001175535   \n",
       "3                   Applied Materials, Inc.  0000006951   \n",
       "4                       Garrett Motion Inc.        None   \n",
       "...                                     ...         ...   \n",
       "229736  Memorial Resource Development Corp.  0001599222   \n",
       "229737                  Intersect ENT, Inc.  0001271214   \n",
       "229738                Paycom Software, Inc.  0001590955   \n",
       "229739               DarÃ© Bioscience, Inc.  0001701808   \n",
       "229740              Powell Industries, Inc.  0000080420   \n",
       "\n",
       "            company_names_database  similarity_scores  Year Month Day  \n",
       "0                EOG RESOURCES INC                100  2020   Jun   1  \n",
       "1                 EATON VANCE CORP                100  2020   May  20  \n",
       "2                  WHITESTONE REIT                100  2020   May   8  \n",
       "3            APPLIED MATERIALS INC                100  2020   May  30  \n",
       "4                             None                  0  2020   May  11  \n",
       "...                            ...                ...   ...   ...  ..  \n",
       "229736  MEMORIAL RESOURCE DEV CORP                 92  2015   May   6  \n",
       "229737           INTERSECT ENT INC                100  2015   May   6  \n",
       "229738         PAYCOM SOFTWARE INC                100  2015   May   6  \n",
       "229739         DARE BIOSCIENCE INC                 97  2015   May   6  \n",
       "229740       POWELL INDUSTRIES INC                100  2015   May   6  \n",
       "\n",
       "[229741 rows x 12 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('1989-12-30 00:00:00'),\n",
       " Timestamp('1990-12-30 00:00:00'),\n",
       " Timestamp('1991-12-30 00:00:00'),\n",
       " Timestamp('1992-12-30 00:00:00'),\n",
       " Timestamp('1993-12-30 00:00:00'),\n",
       " Timestamp('1994-12-30 00:00:00'),\n",
       " Timestamp('1995-12-30 00:00:00'),\n",
       " Timestamp('1996-12-30 00:00:00'),\n",
       " Timestamp('1997-12-30 00:00:00'),\n",
       " Timestamp('1998-12-30 00:00:00'),\n",
       " Timestamp('1999-12-30 00:00:00'),\n",
       " Timestamp('2000-12-30 00:00:00'),\n",
       " Timestamp('2001-12-30 00:00:00'),\n",
       " Timestamp('2002-12-30 00:00:00'),\n",
       " Timestamp('2003-12-30 00:00:00'),\n",
       " Timestamp('2004-12-30 00:00:00'),\n",
       " Timestamp('2005-12-30 00:00:00'),\n",
       " Timestamp('2006-12-30 00:00:00'),\n",
       " Timestamp('2007-12-30 00:00:00'),\n",
       " Timestamp('2008-12-30 00:00:00'),\n",
       " Timestamp('2009-12-30 00:00:00'),\n",
       " Timestamp('2010-12-30 00:00:00'),\n",
       " Timestamp('2011-12-30 00:00:00'),\n",
       " Timestamp('2012-12-30 00:00:00'),\n",
       " Timestamp('2013-12-30 00:00:00'),\n",
       " Timestamp('2014-12-30 00:00:00'),\n",
       " Timestamp('2015-12-30 00:00:00'),\n",
       " Timestamp('2016-12-30 00:00:00'),\n",
       " Timestamp('2017-12-30 00:00:00'),\n",
       " Timestamp('2018-12-30 00:00:00'),\n",
       " Timestamp('2019-12-31 00:00:00'),\n",
       " Timestamp('2020-12-30 00:00:00'),\n",
       " Timestamp('2021-12-30 00:00:00')]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDict['0000821189']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiscalyears = []\n",
    "nonevals = []\n",
    "for i in range(len(df)):\n",
    "    cik = df['CIK'][i]\n",
    "    if cik==None:\n",
    "        fiscalyears.append(None)\n",
    "        continue\n",
    "    year = int(df['Year'][i])\n",
    "    #print(year)\n",
    "    try:\n",
    "        timestamp = myDict[cik][year-1989]\n",
    "        datadate = timestamp.day\n",
    "        datamonth = timestamp.month\n",
    "        calldate = int(df['Day'][i])\n",
    "        callmonth = toint(df['Month'][i])\n",
    "        yr = year\n",
    "        if callmonth < datamonth:\n",
    "            yr = year - 1\n",
    "        elif callmonth > datamonth:\n",
    "            yr = year\n",
    "        elif callmonth == datamonth:\n",
    "            if calldate <= datadate:\n",
    "                yr = year - 1\n",
    "            else:\n",
    "                yr = year\n",
    "        fiscalyears.append(yr)\n",
    "    except:\n",
    "        fiscalyears.append(None)\n",
    "        nonevals.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229741"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fiscalyears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fyear'] = fiscalyears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Field1</th>\n",
       "      <th>Field2_Text</th>\n",
       "      <th>Field3</th>\n",
       "      <th>tickers</th>\n",
       "      <th>company_names_seekingalpha</th>\n",
       "      <th>CIK</th>\n",
       "      <th>company_names_database</th>\n",
       "      <th>similarity_scores</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>fyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...</td>\n",
       "      <td>Jun.  1, 2020  2:30 PM ET</td>\n",
       "      <td>EOG Resources, Inc. (EOG)</td>\n",
       "      <td>EOG Resources, Inc. (NYSE:EOG) AllianceBernste...</td>\n",
       "      <td>EOG</td>\n",
       "      <td>EOG Resources, Inc.</td>\n",
       "      <td>0000821189</td>\n",
       "      <td>EOG RESOURCES INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jun</td>\n",
       "      <td>1</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...</td>\n",
       "      <td>May 20, 2020  5:35 PM ET</td>\n",
       "      <td>Eaton Vance Corp. (EV)</td>\n",
       "      <td>Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...</td>\n",
       "      <td>EV</td>\n",
       "      <td>Eaton Vance Corp.</td>\n",
       "      <td>0000350797</td>\n",
       "      <td>EATON VANCE CORP</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>20</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...</td>\n",
       "      <td>May  8, 2020  5:25 PM ET</td>\n",
       "      <td>Whitestone REIT (WSR)</td>\n",
       "      <td>Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...</td>\n",
       "      <td>WSR</td>\n",
       "      <td>Whitestone REIT</td>\n",
       "      <td>0001175535</td>\n",
       "      <td>WHITESTONE REIT</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>8</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Applied Materials Inc (AMAT) CEO Gary Dickerso...</td>\n",
       "      <td>May 30, 2020  1:22 AM ET</td>\n",
       "      <td>Applied Materials, Inc. (AMAT)</td>\n",
       "      <td>Applied Materials Inc (NASDAQ:AMAT)  2020 Bern...</td>\n",
       "      <td>AMAT</td>\n",
       "      <td>Applied Materials, Inc.</td>\n",
       "      <td>0000006951</td>\n",
       "      <td>APPLIED MATERIALS INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>30</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Garrett Motion Inc. (GTX) CEO Olivier Rabiller...</td>\n",
       "      <td>May 11, 2020  5:16 PM ET</td>\n",
       "      <td>Garrett Motion Inc. (GTX)</td>\n",
       "      <td>Start Time: 08:30 January  1, 0000  9:26 AM ET...</td>\n",
       "      <td>GTX</td>\n",
       "      <td>Garrett Motion Inc.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...   \n",
       "1  Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...   \n",
       "2  Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...   \n",
       "3  Applied Materials Inc (AMAT) CEO Gary Dickerso...   \n",
       "4  Garrett Motion Inc. (GTX) CEO Olivier Rabiller...   \n",
       "\n",
       "                      Field1                     Field2_Text  \\\n",
       "0  Jun.  1, 2020  2:30 PM ET       EOG Resources, Inc. (EOG)   \n",
       "1   May 20, 2020  5:35 PM ET          Eaton Vance Corp. (EV)   \n",
       "2   May  8, 2020  5:25 PM ET           Whitestone REIT (WSR)   \n",
       "3   May 30, 2020  1:22 AM ET  Applied Materials, Inc. (AMAT)   \n",
       "4   May 11, 2020  5:16 PM ET       Garrett Motion Inc. (GTX)   \n",
       "\n",
       "                                              Field3 tickers  \\\n",
       "0  EOG Resources, Inc. (NYSE:EOG) AllianceBernste...     EOG   \n",
       "1  Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...      EV   \n",
       "2  Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...     WSR   \n",
       "3  Applied Materials Inc (NASDAQ:AMAT)  2020 Bern...    AMAT   \n",
       "4  Start Time: 08:30 January  1, 0000  9:26 AM ET...     GTX   \n",
       "\n",
       "  company_names_seekingalpha         CIK company_names_database  \\\n",
       "0        EOG Resources, Inc.  0000821189      EOG RESOURCES INC   \n",
       "1          Eaton Vance Corp.  0000350797       EATON VANCE CORP   \n",
       "2            Whitestone REIT  0001175535        WHITESTONE REIT   \n",
       "3    Applied Materials, Inc.  0000006951  APPLIED MATERIALS INC   \n",
       "4        Garrett Motion Inc.        None                   None   \n",
       "\n",
       "   similarity_scores  Year Month Day   fyear  \n",
       "0                100  2020   Jun   1  2019.0  \n",
       "1                100  2020   May  20  2019.0  \n",
       "2                100  2020   May   8  2019.0  \n",
       "3                100  2020   May  30  2019.0  \n",
       "4                  0  2020   May  11     NaN  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229741"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new1 = df.mask(df.eq('None')).dropna().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Field1</th>\n",
       "      <th>Field2_Text</th>\n",
       "      <th>Field3</th>\n",
       "      <th>tickers</th>\n",
       "      <th>company_names_seekingalpha</th>\n",
       "      <th>CIK</th>\n",
       "      <th>company_names_database</th>\n",
       "      <th>similarity_scores</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>fyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...</td>\n",
       "      <td>Jun.  1, 2020  2:30 PM ET</td>\n",
       "      <td>EOG Resources, Inc. (EOG)</td>\n",
       "      <td>EOG Resources, Inc. (NYSE:EOG) AllianceBernste...</td>\n",
       "      <td>EOG</td>\n",
       "      <td>EOG Resources, Inc.</td>\n",
       "      <td>0000821189</td>\n",
       "      <td>EOG RESOURCES INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jun</td>\n",
       "      <td>1</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...</td>\n",
       "      <td>May 20, 2020  5:35 PM ET</td>\n",
       "      <td>Eaton Vance Corp. (EV)</td>\n",
       "      <td>Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...</td>\n",
       "      <td>EV</td>\n",
       "      <td>Eaton Vance Corp.</td>\n",
       "      <td>0000350797</td>\n",
       "      <td>EATON VANCE CORP</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>20</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...</td>\n",
       "      <td>May  8, 2020  5:25 PM ET</td>\n",
       "      <td>Whitestone REIT (WSR)</td>\n",
       "      <td>Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...</td>\n",
       "      <td>WSR</td>\n",
       "      <td>Whitestone REIT</td>\n",
       "      <td>0001175535</td>\n",
       "      <td>WHITESTONE REIT</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>8</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Applied Materials Inc (AMAT) CEO Gary Dickerso...</td>\n",
       "      <td>May 30, 2020  1:22 AM ET</td>\n",
       "      <td>Applied Materials, Inc. (AMAT)</td>\n",
       "      <td>Applied Materials Inc (NASDAQ:AMAT)  2020 Bern...</td>\n",
       "      <td>AMAT</td>\n",
       "      <td>Applied Materials, Inc.</td>\n",
       "      <td>0000006951</td>\n",
       "      <td>APPLIED MATERIALS INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>30</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Park Hotels &amp; Resorts, Inc. (PK) CEO Thomas Ba...</td>\n",
       "      <td>May 11, 2020  5:10 PM ET</td>\n",
       "      <td>Park Hotels &amp; Resorts Inc. (PK)</td>\n",
       "      <td>Park Hotels &amp; Resorts, Inc. (NYSE:PK) Q1 2020 ...</td>\n",
       "      <td>PK</td>\n",
       "      <td>Park Hotels &amp; Resorts Inc.</td>\n",
       "      <td>0001617406</td>\n",
       "      <td>PARK HOTELS &amp; RESORTS</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>11</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...   \n",
       "1  Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...   \n",
       "2  Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...   \n",
       "3  Applied Materials Inc (AMAT) CEO Gary Dickerso...   \n",
       "4  Park Hotels & Resorts, Inc. (PK) CEO Thomas Ba...   \n",
       "\n",
       "                      Field1                      Field2_Text  \\\n",
       "0  Jun.  1, 2020  2:30 PM ET        EOG Resources, Inc. (EOG)   \n",
       "1   May 20, 2020  5:35 PM ET           Eaton Vance Corp. (EV)   \n",
       "2   May  8, 2020  5:25 PM ET            Whitestone REIT (WSR)   \n",
       "3   May 30, 2020  1:22 AM ET   Applied Materials, Inc. (AMAT)   \n",
       "4   May 11, 2020  5:10 PM ET  Park Hotels & Resorts Inc. (PK)   \n",
       "\n",
       "                                              Field3 tickers  \\\n",
       "0  EOG Resources, Inc. (NYSE:EOG) AllianceBernste...     EOG   \n",
       "1  Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...      EV   \n",
       "2  Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...     WSR   \n",
       "3  Applied Materials Inc (NASDAQ:AMAT)  2020 Bern...    AMAT   \n",
       "4  Park Hotels & Resorts, Inc. (NYSE:PK) Q1 2020 ...      PK   \n",
       "\n",
       "   company_names_seekingalpha         CIK company_names_database  \\\n",
       "0         EOG Resources, Inc.  0000821189      EOG RESOURCES INC   \n",
       "1           Eaton Vance Corp.  0000350797       EATON VANCE CORP   \n",
       "2             Whitestone REIT  0001175535        WHITESTONE REIT   \n",
       "3     Applied Materials, Inc.  0000006951  APPLIED MATERIALS INC   \n",
       "4  Park Hotels & Resorts Inc.  0001617406  PARK HOTELS & RESORTS   \n",
       "\n",
       "   similarity_scores  Year Month Day   fyear  \n",
       "0                100  2020   Jun   1  2019.0  \n",
       "1                100  2020   May  20  2019.0  \n",
       "2                100  2020   May   8  2019.0  \n",
       "3                100  2020   May  30  2019.0  \n",
       "4                100  2020   May  11  2019.0  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Jun', 'May', 'Apr', 'Feb', 'Jan', 'Dec', 'Nov', 'Oct', 'Aug',\n",
       "       'Sep', 'Jul', 'Mar'], dtype=object)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Month'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dict = {\n",
    "    'Jun' : '06', 'May' : '05', 'Apr' : '04', 'Feb' : '02', 'Jan' : '01' , 'Dec' : '12', 'Nov' : '11', 'Oct' : '10' , 'Aug' : '08',\n",
    "       'Sep' : '09', 'Jul' : '07', 'Mar' : '03'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_no_list = []\n",
    "for i in range(0,len(df_new)):\n",
    "    month_no_list.append(month_dict[df_new['Month'][i]])\n",
    "df_new['Month_'] = month_no_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_no_list = []\n",
    "for i in range(0,len(df_new)):\n",
    "    if(int(df_new['Day'][i]) >= 1 and int(df_new['Day'][i]) <= 9):\n",
    "        day_no_list.append('0'+ df_new['Day'][i])\n",
    "    else:\n",
    "        day_no_list.append(df_new['Day'][i])\n",
    "    \n",
    "df_new['Day_'] = day_no_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put correct dateyear in each row\n",
    "dateyear_list = []\n",
    "for i in range(0,len(df_new)):\n",
    "    conf_time = df_new['Year'][i] + '-' + f\"{df_new['Month_'][i]}\" + '-' + f\"{df_new['Day_'][i]}\"\n",
    "    \n",
    "    if(conf_time < myDict[df_new['CIK'][i]][int(df_new['Year'][i])-1989].date().strftime('%Y-%m-%d')):\n",
    "         # prev dateyear\n",
    "        dateyear = myDict[df_new['CIK'][i]][int(df_new['Year'][i])-1989-1].date().strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        # same dateyear\n",
    "        dateyear = myDict[df_new['CIK'][i]][int(df_new['Year'][i])-1989].date().strftime('%Y-%m-%d')\n",
    "    dateyear_list.append(dateyear)\n",
    "df_new['dateyear'] = dateyear_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "for i in range(0,len(df_new)):\n",
    "    if(df_new['Year'][i] == df_new['dateyear'][i].replace('-', ' ').split(' ')[0]):\n",
    "        count1 += 1\n",
    "    else:\n",
    "        count2 += 1\n",
    "# count1(conference with same conf_year and dateyear) is more than count2 (conference with different conf_year and dateyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_time_list = []\n",
    "for i in range(0,len(df_new)):\n",
    "    conf_time_list.append(df_new['Year'][i] + '-' + f\"{df_new['Month_'][i]}\" + '-' + f\"{df_new['Day_'][i]}\")\n",
    "df_new['conf_time'] = conf_time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new2 = df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Field1</th>\n",
       "      <th>Field2_Text</th>\n",
       "      <th>Field3</th>\n",
       "      <th>tickers</th>\n",
       "      <th>company_names_seekingalpha</th>\n",
       "      <th>CIK</th>\n",
       "      <th>company_names_database</th>\n",
       "      <th>similarity_scores</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>fyear</th>\n",
       "      <th>Month_</th>\n",
       "      <th>Day_</th>\n",
       "      <th>dateyear</th>\n",
       "      <th>conf_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...</td>\n",
       "      <td>Jun.  1, 2020  2:30 PM ET</td>\n",
       "      <td>EOG Resources, Inc. (EOG)</td>\n",
       "      <td>EOG Resources, Inc. (NYSE:EOG) AllianceBernste...</td>\n",
       "      <td>EOG</td>\n",
       "      <td>EOG Resources, Inc.</td>\n",
       "      <td>0000821189</td>\n",
       "      <td>EOG RESOURCES INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jun</td>\n",
       "      <td>1</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>06</td>\n",
       "      <td>01</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2020-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...</td>\n",
       "      <td>May 20, 2020  5:35 PM ET</td>\n",
       "      <td>Eaton Vance Corp. (EV)</td>\n",
       "      <td>Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...</td>\n",
       "      <td>EV</td>\n",
       "      <td>Eaton Vance Corp.</td>\n",
       "      <td>0000350797</td>\n",
       "      <td>EATON VANCE CORP</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>20</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>05</td>\n",
       "      <td>20</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>2020-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...</td>\n",
       "      <td>May  8, 2020  5:25 PM ET</td>\n",
       "      <td>Whitestone REIT (WSR)</td>\n",
       "      <td>Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...</td>\n",
       "      <td>WSR</td>\n",
       "      <td>Whitestone REIT</td>\n",
       "      <td>0001175535</td>\n",
       "      <td>WHITESTONE REIT</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>8</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>05</td>\n",
       "      <td>08</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2020-05-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...   \n",
       "1  Eaton Vance Corp. (EV) CEO Tom Faust on Q2 202...   \n",
       "2  Whitestone REIT (WSR) CEO Jim Mastandrea on Q1...   \n",
       "\n",
       "                      Field1                Field2_Text  \\\n",
       "0  Jun.  1, 2020  2:30 PM ET  EOG Resources, Inc. (EOG)   \n",
       "1   May 20, 2020  5:35 PM ET     Eaton Vance Corp. (EV)   \n",
       "2   May  8, 2020  5:25 PM ET      Whitestone REIT (WSR)   \n",
       "\n",
       "                                              Field3 tickers  \\\n",
       "0  EOG Resources, Inc. (NYSE:EOG) AllianceBernste...     EOG   \n",
       "1  Eaton Vance Corp. (NYSE:EV)  Q2 2020 Results C...      EV   \n",
       "2  Whitestone REIT (NYSE:WSR) Q1 2020 Earnings Co...     WSR   \n",
       "\n",
       "  company_names_seekingalpha         CIK company_names_database  \\\n",
       "0        EOG Resources, Inc.  0000821189      EOG RESOURCES INC   \n",
       "1          Eaton Vance Corp.  0000350797       EATON VANCE CORP   \n",
       "2            Whitestone REIT  0001175535        WHITESTONE REIT   \n",
       "\n",
       "   similarity_scores  Year Month Day   fyear Month_ Day_    dateyear  \\\n",
       "0                100  2020   Jun   1  2019.0     06   01  2019-12-31   \n",
       "1                100  2020   May  20  2019.0     05   20  2019-10-31   \n",
       "2                100  2020   May   8  2019.0     05   08  2019-12-31   \n",
       "\n",
       "    conf_time  \n",
       "0  2020-06-01  \n",
       "1  2020-05-20  \n",
       "2  2020-05-08  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add quarter column\n",
    "def date_range(start, end, intv):\n",
    "    from datetime import datetime\n",
    "    start = datetime.strptime(start,\"%Y%m%d\")\n",
    "    end = datetime.strptime(end,\"%Y%m%d\")\n",
    "    diff = (end  - start ) / intv\n",
    "    for i in range(intv):\n",
    "        yield (start + diff * i).strftime(\"%Y%m%d\")\n",
    "    yield end.strftime(\"%Y%m%d\")\n",
    "\n",
    "quarters_list = []\n",
    "\n",
    "for i in range(0,len(df_new)):\n",
    "    conf_date = df_new['conf_time'][i].replace('-','')\n",
    "    \n",
    "    dateyear_i = df_new['dateyear'][i].replace('-','')\n",
    "    \n",
    "    dateyear_year = df_new['dateyear'][i].split('-')[0]\n",
    "    dateyear_f = myDict[df_new['CIK'][i]][int(dateyear_year)-1989+1].date().strftime('%Y%m%d')\n",
    "    \n",
    "    intervals = list(date_range(dateyear_i,dateyear_f, 4))\n",
    "    \n",
    "    \n",
    "    if(conf_date >= intervals[0] and conf_date < intervals[1]):\n",
    "        quarters_list.append(1)\n",
    "    elif(conf_date >= intervals[1] and conf_date < intervals[2]):\n",
    "        quarters_list.append(2)\n",
    "    elif(conf_date >= intervals[2] and conf_date < intervals[3]):\n",
    "        quarters_list.append(3)\n",
    "    elif(conf_date >= intervals[3] and conf_date < intervals[4]):\n",
    "        quarters_list.append(4)\n",
    "\n",
    "df_new['quarter'] = quarters_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Field1</th>\n",
       "      <th>Field2_Text</th>\n",
       "      <th>Field3</th>\n",
       "      <th>tickers</th>\n",
       "      <th>company_names_seekingalpha</th>\n",
       "      <th>CIK</th>\n",
       "      <th>company_names_database</th>\n",
       "      <th>similarity_scores</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>fyear</th>\n",
       "      <th>Month_</th>\n",
       "      <th>Day_</th>\n",
       "      <th>dateyear</th>\n",
       "      <th>conf_time</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...</td>\n",
       "      <td>Jun.  1, 2020  2:30 PM ET</td>\n",
       "      <td>EOG Resources, Inc. (EOG)</td>\n",
       "      <td>EOG Resources, Inc. (NYSE:EOG) AllianceBernste...</td>\n",
       "      <td>EOG</td>\n",
       "      <td>EOG Resources, Inc.</td>\n",
       "      <td>0000821189</td>\n",
       "      <td>EOG RESOURCES INC</td>\n",
       "      <td>100</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jun</td>\n",
       "      <td>1</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>06</td>\n",
       "      <td>01</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  EOG Resources, Inc. (EOG) CEO Bill Thomas Pres...   \n",
       "\n",
       "                      Field1                Field2_Text  \\\n",
       "0  Jun.  1, 2020  2:30 PM ET  EOG Resources, Inc. (EOG)   \n",
       "\n",
       "                                              Field3 tickers  \\\n",
       "0  EOG Resources, Inc. (NYSE:EOG) AllianceBernste...     EOG   \n",
       "\n",
       "  company_names_seekingalpha         CIK company_names_database  \\\n",
       "0        EOG Resources, Inc.  0000821189      EOG RESOURCES INC   \n",
       "\n",
       "   similarity_scores  Year Month Day   fyear Month_ Day_    dateyear  \\\n",
       "0                100  2020   Jun   1  2019.0     06   01  2019-12-31   \n",
       "\n",
       "    conf_time  quarter  \n",
       "0  2020-06-01        2  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_sorted1 = df_new.sort_values(by=[\"CIK\",'conf_time'], kind=\"mergesort\").reset_index(drop = True)\n",
    "df_new_sorted2 = df_new.sort_values(by=[\"CIK\",'dateyear','quarter'], kind=\"mergesort\").reset_index(drop = True)\n",
    "df_new_sorted3 = df_new.sort_values(by=[\"CIK\",'dateyear'], kind=\"mergesort\").reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DIVYANSHU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'documents_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-161-6664caf562c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdocuments_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocuments_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'documents'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# removing special characters and stop words from the text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mstop_words_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdocuments_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'documents_cleaned'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdocuments_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'[^a-zA-Z]'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'[^a-zA-Z]'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words_l\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'documents_df' is not defined"
     ]
    }
   ],
   "source": [
    "documents_df = pd.DataFrame(documents_df,columns=['documents'])\n",
    "\n",
    "# removing special characters and stop words from the text\n",
    "stop_words_l=stopwords.words('english')\n",
    "documents_df['documents_cleaned']=documents_df.apply(lambda x: \" \".join(re.sub(r'[^a-zA-Z]',' ',w).lower() for w in x.split() if re.sub(r'[^a-zA-Z]',' ',w).lower() not in stop_words_l) )\n",
    "\n",
    "tfidfvectoriser=TfidfVectorizer()\n",
    "tfidfvectoriser.fit(documents_df.documents_cleaned)\n",
    "tfidf_vectors=tfidfvectoriser.transform(documents_df.documents_cleaned)\n",
    "\n",
    "pairwise_similarities=np.dot(tfidf_vectors,tfidf_vectors.T).toarray()\n",
    "pairwise_differences=euclidean_distances(tfidf_vectors)\n",
    "\n",
    "def most_similar(doc_id,similarity_matrix,matrix):\n",
    "    print (f'Document: {documents_df.iloc[doc_id][\"documents\"]}')\n",
    "    print ('\\n')\n",
    "    print ('Similar Documents:')\n",
    "    if matrix=='Cosine Similarity':\n",
    "        similar_ix=np.argsort(similarity_matrix[doc_id])[::-1]\n",
    "    elif matrix=='Euclidean Distance':\n",
    "        similar_ix=np.argsort(similarity_matrix[doc_id])\n",
    "    for ix in similar_ix:\n",
    "        if ix==doc_id:\n",
    "            continue\n",
    "        print('\\n')\n",
    "        print (f'Document: {documents_df.iloc[ix][\"documents\"]}')\n",
    "        print (f'{matrix} : {similarity_matrix[doc_id][ix]}')\n",
    "\n",
    "most_similar(0,pairwise_similarities,'Cosine Similarity')\n",
    "most_similar(0,pairwise_differences,'Euclidean Distance')              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scores:\n",
    "    def __init__(self):\n",
    "\n",
    "        # tf_idf\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        from nltk.corpus import stopwords\n",
    "        import nltk\n",
    "        nltk.download('stopwords')\n",
    "        import re\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "\n",
    "        # word2Vec\n",
    "        from keras.preprocessing.text import Tokenizer\n",
    "        from keras.preprocessing.sequence import pad_sequences\n",
    "        import gensim\n",
    "        # loading pre-trained embeddings, each word is represented as a 300 dimensional vector\n",
    "        global W2V_PATH\n",
    "        global model_w2v\n",
    "        W2V_PATH = \"GoogleNews-vectors-negative300.bin.gz\"\n",
    "        model_w2v = gensim.models.KeyedVectors.load_word2vec_format(W2V_PATH, binary=True)\n",
    "\n",
    "\n",
    "        # doc2Vec\n",
    "\n",
    "        from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "        from nltk.tokenize import word_tokenize\n",
    "        import nltk\n",
    "        nltk.download('punkt')\n",
    "\n",
    "\n",
    "        # bert\n",
    "\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        global sbert_model\n",
    "        sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "    \n",
    "    def return_score(self,pairwise_similarities,pairwise_differences,matrix):\n",
    "        if matrix=='Cosine Similarity':\n",
    "            score1 = pairwise_similarities[0][1]\n",
    "        elif matrix=='Euclidean Distance':\n",
    "            score1 = pairwise_differences[0][1]\n",
    "        return score1\n",
    "    \n",
    "    def stopword(self,documents_df):\n",
    "        \n",
    "        stop_words_l=stopwords.words('english')\n",
    "        documents_df['documents_cleaned']=documents_df.documents.apply(lambda x: \" \".join(re.sub(r'[^a-zA-Z]',' ',w).lower() for w in x.split() if re.sub(r'[^a-zA-Z]',' ',w).lower() not in stop_words_l) )\n",
    "        return documents_df\n",
    "        \n",
    "    def tf_idf_vectorizer(self,documents_df):\n",
    "        \n",
    "        tfidfvectoriser=TfidfVectorizer()\n",
    "        tfidfvectoriser.fit(documents_df.documents_cleaned)\n",
    "        tfidf_vectors=tfidfvectoriser.transform(documents_df.documents_cleaned)\n",
    "        return tfidfvectoriser,tfidf_vectors\n",
    "    \n",
    "    def doc2Vec(self,documents_df,matrix):\n",
    "        tagged_data = [TaggedDocument(words=word_tokenize(doc), tags=[i]) for i, doc in enumerate(documents_df.documents_cleaned)]\n",
    "        model_d2v = Doc2Vec(vector_size=100,alpha=0.025, min_count=1)\n",
    "\n",
    "        model_d2v.build_vocab(tagged_data)\n",
    "\n",
    "        for epoch in range(100):\n",
    "            model_d2v.train(tagged_data,\n",
    "                        total_examples=model_d2v.corpus_count,\n",
    "                        epochs=model_d2v.epochs)\n",
    "\n",
    "        document_embeddings=np.zeros((documents_df.shape[0],100))\n",
    "\n",
    "        for i in range(len(document_embeddings)):\n",
    "            document_embeddings[i]=model_d2v.docvecs[i]\n",
    "\n",
    "\n",
    "        pairwise_similarities=cosine_similarity(document_embeddings)\n",
    "        pairwise_differences=euclidean_distances(document_embeddings)\n",
    "        \n",
    "        return self.return_score(pairwise_similarities,pairwise_differences,matrix)\n",
    "\n",
    "        \n",
    "    def word2Vec(self,documents_df,matrix):\n",
    "        \n",
    "        tokenizer=Tokenizer()\n",
    "        tokenizer.fit_on_texts(documents_df.documents_cleaned)\n",
    "        tokenized_documents=tokenizer.texts_to_sequences(documents_df.documents_cleaned)\n",
    "        tokenized_paded_documents=pad_sequences(tokenized_documents,maxlen=64,padding='post')\n",
    "        vocab_size = len(tokenizer.word_index)+1\n",
    "        \n",
    "        \n",
    "        # creating embedding matrix, every row is a vector representation from the vocabulary indexed by the tokenizer index. \n",
    "        embedding_matrix=np.zeros((vocab_size,300))\n",
    "        for word,i in tokenizer.word_index.items():\n",
    "            if word in model_w2v:\n",
    "                embedding_matrix[i]=model_w2v[word]\n",
    "        # creating document-word embeddings\n",
    "        document_word_embeddings=np.zeros((len(tokenized_paded_documents),64,300))\n",
    "        for i in range(len(tokenized_paded_documents)):\n",
    "            for j in range(len(tokenized_paded_documents[0])):\n",
    "                document_word_embeddings[i][j]=embedding_matrix[tokenized_paded_documents[i][j]]\n",
    "                \n",
    "        # calculating average of word vectors of a document weighted by tf-idf\n",
    "        document_embeddings=np.zeros((len(tokenized_paded_documents),300))\n",
    "        tfidfvectoriser = self.tf_idf_vectorizer()\n",
    "        words=tfidfvectoriser.get_feature_names()\n",
    "        \n",
    "        for i in range(len(document_word_embeddings)):\n",
    "            for j in range(len(words)):\n",
    "                a = tfidf_vectors[i].toarray().T\n",
    "                document_embeddings[i]+=embedding_matrix[tokenizer.word_index[words[j]]]*a[j]\n",
    "\n",
    "        pairwise_similarities=cosine_similarity(document_embeddings)\n",
    "        pairwise_differences=euclidean_distances(document_embeddings)\n",
    "        \n",
    "        return self.return_score(pairwise_similarities,pairwise_differences,matrix)\n",
    "        \n",
    "        \n",
    "\n",
    "    def tf_idf(self,documents_df,matrix):\n",
    "        \n",
    "        documents_df = self.stopword(documents_df)\n",
    "        tfidfvectoriser,tfidf_vectors = self.tf_idf_vectorizer(documents_df)\n",
    "        \n",
    "        pairwise_similarities = np.dot(tfidf_vectors,tfidf_vectors.T).toarray()\n",
    "        pairwise_differences = euclidean_distances(tfidf_vectors)\n",
    "        \n",
    "        return self.return_score(pairwise_similarities,pairwise_differences,matrix)\n",
    "    \n",
    "    def bert(self,documents_df):\n",
    "        \n",
    "        \n",
    "\n",
    "        document_embeddings = sbert_model.encode(documents_df['documents_cleaned'])\n",
    "\n",
    "        pairwise_similarities=cosine_similarity(document_embeddings)\n",
    "        pairwise_differences=euclidean_distances(document_embeddings)\n",
    "\n",
    "        return self.return_score(pairwise_similarities,pairwise_differences,matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score funcition for calculating score between any two documents\n",
    "def score(documents_df,matrix):\n",
    "    \n",
    "    stop_words_l=stopwords.words('english')\n",
    "    documents_df['documents_cleaned']=documents_df.Field3.apply(lambda x: \" \".join(re.sub(r'[^a-zA-Z]',' ',w).lower() for w in x.split() if re.sub(r'[^a-zA-Z]',' ',w).lower() not in stop_words_l) )\n",
    "\n",
    "    tfidfvectoriser=TfidfVectorizer()\n",
    "    tfidfvectoriser.fit(documents_df.documents_cleaned)\n",
    "    tfidf_vectors=tfidfvectoriser.transform(documents_df.documents_cleaned)\n",
    "\n",
    "    pairwise_similarities=np.dot(tfidf_vectors,tfidf_vectors.T).toarray()\n",
    "    pairwise_differences=euclidean_distances(tfidf_vectors)\n",
    "    \n",
    "    \n",
    "    if matrix=='Cosine Similarity':\n",
    "        score1 = pairwise_similarities[0][1]\n",
    "    elif matrix=='Euclidean Distance':\n",
    "        score1 = pairwise_differences[0][1]\n",
    "    return score1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# per Conference df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_conference = df_new_sorted1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_conference.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_conference1 = df_per_conference[30:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_per_conference1[['CIK','conf_time','Field3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score calculating logic per dateyear\n",
    "\n",
    "x['Cosine_Similarity'] = \"\"\n",
    "x['Euclidean_Distance'] = \"\"\n",
    "\n",
    "index_list = x.index.tolist()\n",
    "\n",
    "for i in range(1,len(x)):\n",
    "\n",
    "\n",
    "    document = x.iloc[i-1:i+1,2].reset_index(drop = True).to_frame()\n",
    "\n",
    "    cosine = score(document,'Cosine Similarity')\n",
    "    euclidean = score(document,'Euclidean Distance')\n",
    "\n",
    "    x['Cosine_Similarity'][index_list[i]] = cosine\n",
    "    x['Euclidean_Distance'][index_list[i]] = euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# per quarter df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_quarter = df_new_sorted2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_quarter2 = df_per_quarter[30:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_agg2 = lambda x: ' '.join(x)\n",
    "df_2 = df_per_quarter2.groupby(['CIK','dateyear','quarter']).agg({'Field3':array_agg2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_2.reset_index(inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = y.loc[y['CIK'] == '0000001750']\n",
    "# a\n",
    "# b = a.loc[a['dateyear'] == '2018-05-30']\n",
    "# b\n",
    "# b.iloc[0:3]\n",
    "# b.index.tolist()\n",
    "# document = y.iloc[0:,3].reset_index(drop = True).to_frame()\n",
    "# score(document,'Cosine Similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['Cosine_Similarity'] = \"\"\n",
    "y['Euclidean_Distance'] = \"\"\n",
    "\n",
    "CIK_list_2 = list(set(y['CIK'].to_list()))\n",
    "\n",
    "for i in range(0,len(CIK_list_2)):\n",
    "    df_temp_cik_2 = y.loc[y['CIK'] == CIK_list_2[i]]\n",
    "    \n",
    "    for i in range(0,len(df_temp_cik_2)):\n",
    "        dateyear_list_2 = list(set(df_temp_cik_2['dateyear'].to_list()))\n",
    "    \n",
    "        \n",
    "        for i in range(0,len(dateyear_list_2)):\n",
    "            df_temp_dateyear_2 = df_temp_cik_2.loc[df_temp_cik_2['dateyear'] == dateyear_list_2[i]]\n",
    "            \n",
    "            index_list = df_temp_dateyear_2.index.tolist()\n",
    "            \n",
    "            for i in range(1,len(df_temp_dateyear_2)):\n",
    "                document = df_temp_dateyear_2.iloc[i-1:i+1,3].reset_index(drop = True).to_frame()\n",
    "                \n",
    "                cosine = score(document,'Cosine Similarity')\n",
    "                euclidean = score(document,'Euclidean Distance')\n",
    "                y['Cosine_Similarity'][index_list[i]] = cosine\n",
    "                y['Euclidean_Distance'][index_list[i]] = euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrays2 = [['0000001750'], ['2007-05-30'],['4']]\n",
    "# i2 = pd.MultiIndex.from_arrays(arrays2, names=('CIK', 'dateyear','quarter'))\n",
    "# t2 = df_3.loc[i]['Field3']\n",
    "# t2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# per dateyear df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_dateyear = df_new_sorted3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_dateyear3 = df_per_dateyear[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_agg3 = lambda x: ' '.join(x)\n",
    "df_3 = df_per_dateyear3.groupby(['CIK','dateyear']).agg({'Field3':array_agg3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = df_3.reset_index(inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score calculating logic per dateyear\n",
    "\n",
    "z['Cosine_Similarity'] = \"\"\n",
    "z['Euclidean_Distance'] = \"\"\n",
    "\n",
    "CIK_list_3 = list(set(z['CIK'].to_list()))\n",
    "\n",
    "for i in range(0,len(CIK_list_3)):\n",
    "    df_temp_cik_3 = z.loc[z['CIK'] == CIK_list_3[i]]\n",
    "    \n",
    "    dateyear_list_3 = list(set(df_temp_cik_3['dateyear'].to_list()))\n",
    "    \n",
    "    dateyear_year = []\n",
    "    for i in range(0,len(dateyear_list_3)):\n",
    "        dateyear_year.append(int(dateyear_list_3[i].split('-')[0]))\n",
    "        \n",
    "    dateyear_year = set(dateyear_year)\n",
    "    \n",
    "    index_list = df_temp_cik_3.index.tolist()\n",
    "\n",
    "    for i in range(1,len(df_temp_cik_3)):\n",
    "        current_year = int(df_temp_cik_3['dateyear'][i].split('-')[0])\n",
    "\n",
    "        \n",
    "        if current_year - 1 in dateyear_year:\n",
    "            document = df_temp_cik_3.iloc[i-1:i+1,2].reset_index(drop = True).to_frame()\n",
    "\n",
    "            cosine = score(document,'Cosine Similarity')\n",
    "            euclidean = score(document,'Euclidean Distance')\n",
    "\n",
    "            z['Cosine_Similarity'][index_list[i]] = cosine\n",
    "            z['Euclidean_Distance'][index_list[i]] = euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c\n",
    "# CIK_list_3\n",
    "# index_list\n",
    "# dateyear_list_3\n",
    "# print(dateyear_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df.sort_values(by= [\"CIK\",\"fyear\",\"Month\",\"Day\"], kind=\"mergesort\", ascending=[True, True, True, True]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = sorted_df.dropna()\n",
    "clean_df = sorted_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = sorted_df[sorted_df['fyear'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
